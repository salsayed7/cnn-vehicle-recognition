{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b64e0610-028b-4cc2-acd8-84048c9422c3",
   "metadata": {},
   "source": [
    "# License Plate Project\n",
    "Live data stream real-time processing is required, speed and accuracy are the main factors.\n",
    "\n",
    "# Incoming Truck\n",
    "<img src=\"../samples/new_truck.jpg\"  width=\"49%\" style=\"float: left; margin: 5px;\">\n",
    "<img src=\"../samples/new_truck_id.png\"  width=\"49%\" style=\"float: left; margin: 5px;\">\n",
    "\n",
    "# Readable License Plate on Truck\n",
    "<img src=\"../samples/truck.jpg\"  width=\"100%\" style=\"float: left; mergin-bottom: 15px;\">\n",
    "\n",
    "# Process Pipeline\n",
    "<div style=\"margin: 10px;\">\n",
    "    <img src=\"../samples/pipeline.jpg\"  width=\"100%\" style=\"float: left;\">\n",
    "</div>\n",
    "\n",
    "# Layers\n",
    "- Truck / Car recognition\n",
    "- License Plate Detection\n",
    "- Spatial Transform of License Plate for better Recognition\n",
    "- License Plate Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a4e576",
   "metadata": {},
   "source": [
    "# Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22ee1153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\saleh\\anaconda3\\lib\\site-packages (4.9.0.80)\n",
      "Requirement already satisfied: torch in c:\\users\\saleh\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: torchvision in c:\\users\\saleh\\anaconda3\\lib\\site-packages (0.17.2)\n",
      "Requirement already satisfied: ultralytics in c:\\users\\saleh\\anaconda3\\lib\\site-packages (8.2.35)\n",
      "Requirement already satisfied: easyocr in c:\\users\\saleh\\anaconda3\\lib\\site-packages (1.7.1)\n",
      "Requirement already satisfied: pytesseract in c:\\users\\saleh\\anaconda3\\lib\\site-packages (0.3.10)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\saleh\\anaconda3\\lib\\site-packages (from opencv-python) (1.23.5)\n",
      "Requirement already satisfied: filelock in c:\\users\\saleh\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\saleh\\anaconda3\\lib\\site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\saleh\\anaconda3\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\saleh\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\saleh\\anaconda3\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\saleh\\anaconda3\\lib\\site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\saleh\\anaconda3\\lib\\site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\saleh\\anaconda3\\lib\\site-packages (from ultralytics) (3.8.4)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\saleh\\anaconda3\\lib\\site-packages (from ultralytics) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\saleh\\anaconda3\\lib\\site-packages (from ultralytics) (2.31.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\saleh\\anaconda3\\lib\\site-packages (from ultralytics) (1.12.0)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\saleh\\anaconda3\\lib\\site-packages (from ultralytics) (4.65.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\saleh\\anaconda3\\lib\\site-packages (from ultralytics) (5.9.0)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\saleh\\anaconda3\\lib\\site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\saleh\\anaconda3\\lib\\site-packages (from ultralytics) (2.1.4)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\saleh\\anaconda3\\lib\\site-packages (from ultralytics) (0.12.2)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in c:\\users\\saleh\\anaconda3\\lib\\site-packages (from ultralytics) (2.0.0)\n",
      "Requirement already satisfied: opencv-python-headless in c:\\users\\saleh\\anaconda3\\lib\\site-packages (from easyocr) (4.9.0.80)\n",
      "Requirement already satisfied: scikit-image in c:\\users\\saleh\\anaconda3\\lib\\site-packages (from easyocr) (0.22.0)\n",
      "Requirement already satisfied: python-bidi in c:\\users\\saleh\\anaconda3\\lib\\site-packages (from easyocr) (0.4.2)\n",
      "Requirement already satisfied: Shapely in c:\\users\\saleh\\anaconda3\\lib\\site-packages (from easyocr) (2.0.4)\n",
      "Requirement already satisfied: pyclipper in c:\\users\\saleh\\anaconda3\\lib\\site-packages (from easyocr) (1.3.0.post5)\n",
      "Requirement already satisfied: ninja in c:\\users\\saleh\\anaconda3\\lib\\site-packages (from easyocr) (1.11.1.1)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\saleh\\anaconda3\\lib\\site-packages (from pytesseract) (23.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\saleh\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\saleh\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\saleh\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\saleh\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\saleh\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\saleh\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\saleh\\anaconda3\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\saleh\\anaconda3\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\saleh\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\saleh\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\saleh\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\saleh\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2024.2.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\saleh\\anaconda3\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\saleh\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: six in c:\\users\\saleh\\anaconda3\\lib\\site-packages (from python-bidi->easyocr) (1.16.0)\n",
      "Requirement already satisfied: imageio>=2.27 in c:\\users\\saleh\\anaconda3\\lib\\site-packages (from scikit-image->easyocr) (2.33.1)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\saleh\\anaconda3\\lib\\site-packages (from scikit-image->easyocr) (2023.4.12)\n",
      "Requirement already satisfied: lazy_loader>=0.3 in c:\\users\\saleh\\anaconda3\\lib\\site-packages (from scikit-image->easyocr) (0.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\saleh\\anaconda3\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\clyent-1.2.2-py3.10.egg-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\et_xmlfile-1.1.0-py3.10.egg-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\idna-3.4.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\inflection-0.5.1-py3.10.egg-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\joblib-1.2.0.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\lazy_object_proxy-1.6.0.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\mkl_service-2.4.0-py3.10.egg-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\navigator_updater-0.4.0.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\numpy-1.26.4.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\openpyxl-3.0.10-py3.10.egg-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\pillow-10.2.0.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\pip-23.3.1-py3.10.egg-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\ply-3.11-py3.10.egg-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\protobuf-3.20.3-py3.10.egg-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\pycurl-7.45.2-py3.10-win-amd64.egg-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\PyDispatcher-2.0.5-py3.10.egg-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\pytz-2023.3.post1.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\pywin32-305.1-py3.10.egg-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\ruamel.yaml.clib-0.2.6.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\setuptools-68.2.2-py3.10.egg-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\clyent-1.2.2-py3.10.egg-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\et_xmlfile-1.1.0-py3.10.egg-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\idna-3.4.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\inflection-0.5.1-py3.10.egg-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\joblib-1.2.0.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\lazy_object_proxy-1.6.0.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\mkl_service-2.4.0-py3.10.egg-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\navigator_updater-0.4.0.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\numpy-1.26.4.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\openpyxl-3.0.10-py3.10.egg-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\pillow-10.2.0.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\pip-23.3.1-py3.10.egg-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\ply-3.11-py3.10.egg-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\protobuf-3.20.3-py3.10.egg-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\pycurl-7.45.2-py3.10-win-amd64.egg-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\PyDispatcher-2.0.5-py3.10.egg-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\pytz-2023.3.post1.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\pywin32-305.1-py3.10.egg-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\ruamel.yaml.clib-0.2.6.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\setuptools-68.2.2-py3.10.egg-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\webencodings-0.5.1-py3.10.egg-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\zstandard-0.19.0-py3.10.egg-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\clyent-1.2.2-py3.10.egg-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\et_xmlfile-1.1.0-py3.10.egg-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\idna-3.4.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\inflection-0.5.1-py3.10.egg-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\joblib-1.2.0.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\lazy_object_proxy-1.6.0.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\mkl_service-2.4.0-py3.10.egg-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\navigator_updater-0.4.0.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\numpy-1.26.4.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\openpyxl-3.0.10-py3.10.egg-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\pillow-10.2.0.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\pip-23.3.1-py3.10.egg-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\ply-3.11-py3.10.egg-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\protobuf-3.20.3-py3.10.egg-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\pycurl-7.45.2-py3.10-win-amd64.egg-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\PyDispatcher-2.0.5-py3.10.egg-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\pytz-2023.3.post1.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\pywin32-305.1-py3.10.egg-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\ruamel.yaml.clib-0.2.6.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\setuptools-68.2.2-py3.10.egg-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\webencodings-0.5.1-py3.10.egg-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\zstandard-0.19.0-py3.10.egg-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\clyent-1.2.2-py3.10.egg-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\et_xmlfile-1.1.0-py3.10.egg-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\idna-3.4.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\inflection-0.5.1-py3.10.egg-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\joblib-1.2.0.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\lazy_object_proxy-1.6.0.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\mkl_service-2.4.0-py3.10.egg-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\navigator_updater-0.4.0.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\numpy-1.26.4.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\openpyxl-3.0.10-py3.10.egg-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\pillow-10.2.0.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\pip-23.3.1-py3.10.egg-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\ply-3.11-py3.10.egg-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\protobuf-3.20.3-py3.10.egg-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\pycurl-7.45.2-py3.10-win-amd64.egg-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\PyDispatcher-2.0.5-py3.10.egg-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\pytz-2023.3.post1.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\pywin32-305.1-py3.10.egg-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\ruamel.yaml.clib-0.2.6.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\setuptools-68.2.2-py3.10.egg-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\clyent-1.2.2-py3.10.egg-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\et_xmlfile-1.1.0-py3.10.egg-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\idna-3.4.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\inflection-0.5.1-py3.10.egg-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\joblib-1.2.0.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\lazy_object_proxy-1.6.0.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\mkl_service-2.4.0-py3.10.egg-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\navigator_updater-0.4.0.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\numpy-1.26.4.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\openpyxl-3.0.10-py3.10.egg-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\pillow-10.2.0.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\pip-23.3.1-py3.10.egg-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\clyent-1.2.2-py3.10.egg-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\et_xmlfile-1.1.0-py3.10.egg-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\idna-3.4.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\inflection-0.5.1-py3.10.egg-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\joblib-1.2.0.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\lazy_object_proxy-1.6.0.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\mkl_service-2.4.0-py3.10.egg-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\navigator_updater-0.4.0.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\numpy-1.26.4.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\openpyxl-3.0.10-py3.10.egg-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\pillow-10.2.0.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping c:\\Users\\Saleh\\anaconda3\\Lib\\site-packages\\pip-23.3.1-py3.10.egg-info due to invalid metadata entry 'name'\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python torch torchvision ultralytics easyocr pytesseract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f405f1-5c7e-4c5d-b675-426d3665abb5",
   "metadata": {},
   "source": [
    "# Reload modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87cda89d-ed05-4bde-a0f7-9b9341de7cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e54a7e-94ae-4eca-959a-d599a3d7ebcb",
   "metadata": {},
   "source": [
    "# ================ Run all cells below one by one ==================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8abd1b9-dee0-4977-94a1-c20ad0fb1e23",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c62b7e6-f2fb-4e04-860d-3c438130f154",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you are using CPU you may see a warning above caused by easyocr, you can ignore it!\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import cv2\n",
    "import math\n",
    "import time\n",
    "import traceback\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# Imports all pre-trained YOLOv5, YOLOv8, YOLOv9 and in the future YOLOv10 models (COCO dataset with 80 classes), they will be automatically downloaded if not available\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Imports all other pre-trained detection models needed (COCO dataset with 80 classes), they will be automatically downloaded if they are not available\n",
    "from torchvision.models.detection import *\n",
    "from torchvision.io.image import read_image\n",
    "from torchvision.utils import draw_bounding_boxes\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import IPython\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# OCR\n",
    "import pytesseract   # pip install pytesseract\n",
    "import easyocr  # pip install easyocr\n",
    "\n",
    "# Install this from \"https://github.com/UB-Mannheim/tesseract/wiki\"\n",
    "pytesseract.pytesseract.tesseract_cmd = 'C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract.exe'\n",
    "\n",
    "# Init on english and german characters\n",
    "reader = easyocr.Reader(['en', 'de'])\n",
    "\n",
    "print(\"If you are using CPU you may see a warning above caused by easyocr, you can ignore it!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d149f4-a9ee-46be-880f-c96e88a673d7",
   "metadata": {},
   "source": [
    "# Determining first priority for GPU for better performance if available; otherwise, settle for CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "672220c7-9d00-4d9e-b031-910c939adda5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are using: cpu (Device)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"You are using:\",device,\"(Device)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8332960-61b7-4f74-815c-ea44a418725a",
   "metadata": {},
   "source": [
    "# Run this cell if you are using any model from Pytorch, it transforms input image to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08e3c8b0-f1de-4ee3-aceb-8f527633d719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good, run the next!\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    # transforms.Resize((300, 300)), # resizes the input image into 300x300 before processing but it is not needed here\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "print(\"Good, run the next!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466bf6da-8f2d-4264-aabd-77996cffb098",
   "metadata": {},
   "source": [
    "# Define custom classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5f8a200-f409-4738-89ee-70022fb8184e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Definitions initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "# This is a new class definition that describes a Detection Model object, where detections can be stored and averages can be calculated, this workflow is based on the RAM size because it stores data temporarily, I wanted to rebuild the code so it works with file save and file read and that every model inferences the whole video then the next model comes but I still wanted to test with camera on a live feed so I kept it as is in the end. This class downloads, loads and initializes all models before the beginning of tests.\n",
    "class DetectionModel():\n",
    "    def __init__(self, concept, backbone, model, weights, reference, color=None, custom=False):\n",
    "        self.concept = concept\n",
    "        self.backbone = backbone\n",
    "        self.model = model if custom==True else model(weights) if concept==\"YOLO\" else model(weights=weights.DEFAULT)\n",
    "        if concept not in [\"YOLO\", \"OCR\"]:\n",
    "            self.model.to(device)\n",
    "            self.model.eval()\n",
    "        self.weights = weights\n",
    "        self.reference = reference\n",
    "        self.color = color\n",
    "        self.custom = custom\n",
    "        self.detections = []\n",
    "        self.plates_detections = []\n",
    "        self.plates_recognitions = []\n",
    "        self.vehicleModel = -1\n",
    "        self.plateModel = -1\n",
    "        self.textModel = -1\n",
    "\n",
    "    def addDetection(self, detection):\n",
    "        self.detections.append(detection)\n",
    "\n",
    "    def addPlateDetection(self, plate_detection):\n",
    "        self.plates_detections.append(plate_detection)\n",
    "\n",
    "    def addPlateRecognition(self, plate_recognition):\n",
    "        self.plates_recognitions.append(plate_recognition)\n",
    "\n",
    "    def getDetections(self):\n",
    "        return self.detections\n",
    "\n",
    "    def clearDetections(self):\n",
    "        self.detections = []\n",
    "\n",
    "    def detectionsCount(self, child=None):\n",
    "        if child is not None:\n",
    "            if child==\"plateDetection\": return len(self.plates_detections)\n",
    "            else: return len(self.plates_recognitions)\n",
    "        return len(self.detections)\n",
    "\n",
    "    def inferencesCount(self, child=None):\n",
    "        length = 0\n",
    "        addedIds = []\n",
    "        if child is None:\n",
    "            if len(self.detections)>0:\n",
    "                for i in range(len(self.detections)):\n",
    "                    if self.detections[i].id not in addedIds:\n",
    "                        addedIds.append(self.detections[i].id)\n",
    "        else:\n",
    "            if child==\"plateDetection\":\n",
    "                if len(self.plates_detections)>0:\n",
    "                    for i in range(len(self.plates_detections)):\n",
    "                        if self.plates_detections[i].id not in addedIds:\n",
    "                            addedIds.append(self.plates_detections[i].id)\n",
    "            elif child==\"plateRecognition\":\n",
    "                if len(self.plates_recognitions)>0:\n",
    "                    for i in range(len(self.plates_recognitions)):\n",
    "                        if self.plates_recognitions[i].id not in addedIds:\n",
    "                            addedIds.append(self.plates_recognitions[i].id)\n",
    "        return len(addedIds)\n",
    "\n",
    "    def getAveragePrecision(self, child=None):\n",
    "        sum=0.0\n",
    "        avg=0.0\n",
    "        if child is None:\n",
    "            if len(self.detections)>0:\n",
    "                for i in range(len(self.detections)):\n",
    "                    sum+=self.detections[i].precision\n",
    "                avg = sum/len(self.detections)\n",
    "        else:\n",
    "            if child==\"plateDetection\":\n",
    "                if len(self.plates_detections)>0:\n",
    "                    for i in range(len(self.plates_detections)):\n",
    "                        sum+=self.plates_detections[i].precision\n",
    "                    avg = sum/len(self.plates_detections)\n",
    "            elif child==\"plateRecognition\":\n",
    "                if len(self.plates_recognitions)>0:\n",
    "                    for i in range(len(self.plates_recognitions)):\n",
    "                        sum+=self.plates_recognitions[i].precision\n",
    "                    avg = sum/len(self.plates_recognitions)\n",
    "        return avg.item() if torch.is_tensor(avg) else avg\n",
    "\n",
    "    def getMaxPrecision(self, child=None):\n",
    "        max=0.0\n",
    "        if child is None:\n",
    "            for i in range(len(self.detections)):\n",
    "                if max<self.detections[i].precision:\n",
    "                    max=self.detections[i].precision\n",
    "        else:\n",
    "            if child==\"plateDetection\":\n",
    "                for i in range(len(self.plates_detections)):\n",
    "                    if max<self.plates_detections[i].precision:\n",
    "                        max=self.plates_detections[i].precision\n",
    "            elif child==\"plateRecognition\":\n",
    "                for i in range(len(self.plates_recognitions)):\n",
    "                    if max<self.plates_recognitions[i].precision:\n",
    "                        max=self.plates_recognitions[i].precision\n",
    "        return max.item() if torch.is_tensor(max) else max\n",
    "\n",
    "    def getMinPrecision(self, child=None):\n",
    "        min=9999999.99\n",
    "        if child is None:\n",
    "            for i in range(len(self.detections)):\n",
    "                if min>self.detections[i].precision:\n",
    "                    min=self.detections[i].precision\n",
    "        else:\n",
    "            if child==\"plateDetection\":\n",
    "                for i in range(len(self.plates_detections)):\n",
    "                    if min>self.plates_detections[i].precision:\n",
    "                        min=self.plates_detections[i].precision\n",
    "            elif child==\"plateRecognition\":\n",
    "                for i in range(len(self.plates_recognitions)):\n",
    "                        if min>self.plates_recognitions[i].precision:\n",
    "                            min=self.plates_recognitions[i].precision\n",
    "        return 0.0 if min==9999999.99 else min.item() if torch.is_tensor(min) else min\n",
    "\n",
    "    def getAverageInferenceSpeed(self, child=None):\n",
    "        sum=0.0\n",
    "        avg=0.0\n",
    "        addedFrames=[]\n",
    "        if child is None:\n",
    "            if len(self.detections)>0:\n",
    "                for i in range(len(self.detections)):\n",
    "                    if self.detections[i].frame not in addedFrames:\n",
    "                        sum+=self.detections[i].speed\n",
    "                        addedFrames.append(self.detections[i].frame)\n",
    "                avg = sum/len(addedFrames) if len(addedFrames)>0 else 0.0\n",
    "        else:\n",
    "            if child==\"plateDetection\":\n",
    "                if len(self.plates_detections)>0:\n",
    "                    for i in range(len(self.plates_detections)):\n",
    "                        if self.plates_detections[i].frame not in addedFrames:\n",
    "                            sum+=self.plates_detections[i].speed\n",
    "                            addedFrames.append(self.plates_detections[i].frame)\n",
    "                    avg = sum/len(addedFrames) if len(addedFrames)>0 else 0.0\n",
    "            elif child==\"plateRecognition\":\n",
    "                if len(self.plates_recognitions)>0:\n",
    "                    for i in range(len(self.plates_recognitions)):\n",
    "                        if self.plates_recognitions[i].frame not in addedFrames:\n",
    "                            sum+=self.plates_recognitions[i].speed\n",
    "                            addedFrames.append(self.plates_recognitions[i].frame)\n",
    "                    avg = sum/len(addedFrames) if len(addedFrames)>0 else 0.0\n",
    "        return avg\n",
    "\n",
    "    def getMaxInferenceSpeed(self, child=None):\n",
    "        max=0.0\n",
    "        addedFrames=[]\n",
    "        if child is None:\n",
    "            for i in range(len(self.detections)):\n",
    "                if max<self.detections[i].speed and self.detections[i].frame not in addedFrames:\n",
    "                    max=self.detections[i].speed\n",
    "                    addedFrames.append(self.detections[i].frame)\n",
    "        else:\n",
    "            if child==\"plateDetection\":\n",
    "                for i in range(len(self.plates_detections)):\n",
    "                    if max<self.plates_detections[i].speed and self.plates_detections[i].frame not in addedFrames:\n",
    "                        max=self.plates_detections[i].speed\n",
    "                        addedFrames.append(self.plates_detections[i].frame)\n",
    "            elif child==\"plateRecognition\":\n",
    "                for i in range(len(self.plates_recognitions)):\n",
    "                    if max<self.plates_recognitions[i].speed and self.plates_recognitions[i].frame not in addedFrames:\n",
    "                        max=self.plates_recognitions[i].speed\n",
    "                        addedFrames.append(self.plates_recognitions[i].frame)\n",
    "        return max\n",
    "\n",
    "    def getMinInferenceSpeed(self, child=None):\n",
    "        min=9999999.99\n",
    "        addedFrames=[]\n",
    "        if child is None:\n",
    "            for i in range(len(self.detections)):\n",
    "                if min>self.detections[i].speed and self.detections[i].frame not in addedFrames:\n",
    "                    min=self.detections[i].speed\n",
    "                    addedFrames.append(self.detections[i].frame)\n",
    "        else:\n",
    "            if child==\"plateDetection\":\n",
    "                for i in range(len(self.plates_detections)):\n",
    "                    if min>self.plates_detections[i].speed and self.plates_detections[i].frame not in addedFrames:\n",
    "                        min=self.plates_detections[i].speed\n",
    "                        addedFrames.append(self.plates_detections[i].frame)\n",
    "            elif child==\"plateRecognition\":\n",
    "                for i in range(len(self.plates_recognitions)):\n",
    "                    if min>self.plates_recognitions[i].speed and self.plates_recognitions[i].frame not in addedFrames:\n",
    "                        min=self.plates_recognitions[i].speed\n",
    "                        addedFrames.append(self.plates_recognitions[i].frame)\n",
    "        return 0.0 if min==9999999.99 else min\n",
    "\n",
    "    def filterPrecisionsBelow(self, minPrecision, child=None):\n",
    "        newDetections = []\n",
    "        if child is None:\n",
    "            for i in range(len(self.detections)):\n",
    "                if self.detections[i].precision>=minPrecision:\n",
    "                    newDetections.append(self.detections[i])\n",
    "            self.detections = newDetections\n",
    "        else:\n",
    "            if child==\"plateDetection\":\n",
    "                for i in range(len(self.plates_detections)):\n",
    "                    if self.plates_detections[i].precision>=minPrecision:\n",
    "                        newDetections.append(self.plates_detections[i])\n",
    "                self.plates_detections = newDetections\n",
    "            elif child==\"plateRecognition\":\n",
    "                for i in range(len(self.plates_recognitions)):\n",
    "                    if self.plates_recognitions[i].precision>=minPrecision:\n",
    "                        newDetections.append(self.plates_recognitions[i])\n",
    "                self.plates_recognitions = newDetections\n",
    "\n",
    "    def toString(self, withPlates=True, withTexts=True):\n",
    "        text = \"\"\n",
    "        text += f'Model: {self.reference} \\n'\n",
    "        text += f'Best Precision: {self.getMaxPrecision():.2f} \\n'\n",
    "        text += f'Average Precision: {self.getAveragePrecision():.2f}s \\n'\n",
    "        text += f'Worst Precision: {self.getMinPrecision()} \\n'\n",
    "        text += f'Best Inference Speed: {self.getMinInferenceSpeed():.5f}s \\n'\n",
    "        text += f'Best Inference Speed: {self.getAverageInferenceSpeed():.5f}s \\n'\n",
    "        text += f'Worst Inference Speed: {self.getMaxInferenceSpeed():.5f}s \\n'\n",
    "        text += f'Total Detections: {self.detectionsCount()} \\n'\n",
    "        text += f'Total Inferences: {self.inferencesCount()}'\n",
    "\n",
    "        if withPlates==True:\n",
    "            text += \"\\n\\n\"\n",
    "            text += f'Plate Best Precision: {self.getMaxPrecision(\"plateDetection\"):.2f} \\n'\n",
    "            text += f'Plate Average Precision: {self.getAveragePrecision(\"plateDetection\"):.2f}s \\n'\n",
    "            text += f'Plate Worst Precision: {self.getMinPrecision(\"plateDetection\")} \\n'\n",
    "            text += f'Plate Best Inference Speed: {self.getMinInferenceSpeed(\"plateDetection\"):.5f}s \\n'\n",
    "            text += f'Plate Best Inference Speed: {self.getAverageInferenceSpeed(\"plateDetection\"):.5f}s \\n'\n",
    "            text += f'Plate Worst Inference Speed: {self.getMaxInferenceSpeed(\"plateDetection\"):.5f}s \\n'\n",
    "            text += f'Plate Total Detections: {self.detectionsCount(\"plateDetection\")} \\n'\n",
    "            text += f'Plate Total Inferences: {self.inferencesCount(\"plateDetection\")}'\n",
    "\n",
    "        if withTexts==True:\n",
    "            text += \"\\n\\n\"\n",
    "            text += f'Plate Text Best Precision: {self.getMaxPrecision(\"plateRecognition\"):.2f} \\n'\n",
    "            text += f'Plate Text Average Precision: {self.getAveragePrecision(\"plateRecognition\"):.2f}s \\n'\n",
    "            text += f'Plate Text Worst Precision: {self.getMinPrecision(\"plateRecognition\")} \\n'\n",
    "            text += f'Plate Text Best Inference Speed: {self.getMinInferenceSpeed(\"plateRecognition\"):.5f}s \\n'\n",
    "            text += f'Plate Text Best Inference Speed: {self.getAverageInferenceSpeed(\"plateRecognition\"):.5f}s \\n'\n",
    "            text += f'Plate Text Worst Inference Speed: {self.getMaxInferenceSpeed(\"plateRecognition\"):.5f}s \\n'\n",
    "            text += f'Plate Text Total Detections: {self.detectionsCount(\"plateRecognition\")} \\n'\n",
    "            text += f'Plate Text Total Inferences: {self.inferencesCount(\"plateRecognition\")}'\n",
    "\n",
    "        text += \"\\n\\n\"\n",
    "        return text\n",
    "\n",
    "    def printDetections(self):\n",
    "        for i in range(len(self.detections)):\n",
    "            print(self.detections[i].toString())\n",
    "            print()\n",
    "\n",
    "    def printPlateDetections(self):\n",
    "        for i in range(len(self.plates_detections)):\n",
    "            print(self.plates_detections[i].toString())\n",
    "            print()\n",
    "\n",
    "    def printPlateRecognitions(self):\n",
    "        for i in range(len(self.plates_recognitions)):\n",
    "            print(self.plates_recognitions[i].toString())\n",
    "            print()\n",
    "    \n",
    "    def printResults(self):\n",
    "        print(self.toString())\n",
    "\n",
    "# This class represents a Detection Result, it is saved into the detections array in the Detection Model object\n",
    "class DetectionResult():\n",
    "    def __init__(self, model, label, precision, speed, device=None, source=None, frame=None, id=None, boundingBox=None, details=None, content=None):\n",
    "        self.model = model\n",
    "        self.label = label\n",
    "        self.precision = precision.item() if torch.is_tensor(precision) else precision\n",
    "        self.speed = speed.item() if torch.is_tensor(speed) else speed\n",
    "        self.content = content\n",
    "        self.device = device\n",
    "        self.source = source\n",
    "        self.frame = frame\n",
    "        self.boundingBox = boundingBox\n",
    "        self.details = details\n",
    "        self.id = id\n",
    "\n",
    "    def toString(self):\n",
    "        text = \"\"\n",
    "        text += f'ID: {self.id}, '\n",
    "        text += f'Model: {self.model}, '\n",
    "        text += f'Label: {self.label}, '\n",
    "        text += f'Precision: {self.precision:.2f}%, '\n",
    "        text += f'Speed: {self.speed:.3f}s, '\n",
    "        text += f'Content: {self.content}, '\n",
    "        text += f'Device: {self.device}, '\n",
    "        text += f'Source: {self.source}, '\n",
    "        text += f'Frame: {self.frame}, '\n",
    "        text += f'BoundingBox: {self.boundingBox[0]} {self.boundingBox[1]} {self.boundingBox[2]} {self.boundingBox[3]}, ' if self.boundingBox is not None else \"\"\n",
    "        text += f'Details: {self.details}'\n",
    "        return text\n",
    "\n",
    "print(\"Definitions initialized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9cf317-09b1-45e4-b700-b187a2e9c805",
   "metadata": {},
   "source": [
    "# Initialize (and download) detection models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40077c3e-6d31-43bd-afa0-89b7b0c88045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initialized (and imported) vehicle detectors!\n"
     ]
    }
   ],
   "source": [
    "# This defines all the models we want to work with on vehicle detection, we can import any model we want above and add it in this array eventually.\n",
    "# Defining a new model takes the concept name as the first parameter, the backbone name as the second parameter, the model object in the third, the pretrained weights name in fourth,  a custom given name for the model as fifth parameter and a color tupel in the last parameter.\n",
    "VEHICLE_DETECTION_MODELS = [\n",
    "    DetectionModel(\"FCOS\", \"resnet50_fpn\", fcos_resnet50_fpn, FCOS_ResNet50_FPN_Weights, \"fcos_resnet\", (0,234,255)),\n",
    "    DetectionModel(\"RetinaNet\", \"resnet50_fpn\", retinanet_resnet50_fpn, RetinaNet_ResNet50_FPN_Weights, \"retinanet_resnet\", (255,255,0)),\n",
    "    DetectionModel(\"RetinaNet\", \"resnet50_fpn_v2\", retinanet_resnet50_fpn_v2, RetinaNet_ResNet50_FPN_V2_Weights, \"retinanet_resnet_v2\", (0,234,255)),\n",
    "    DetectionModel(\"FasterRCNN\", \"resnet50_fpn\", fasterrcnn_resnet50_fpn, FasterRCNN_ResNet50_FPN_Weights, \"faster_rcnn_resnet\", (170,0,255)),\n",
    "    DetectionModel(\"FasterRCNN\", \"resnet50_fpn_v2\", fasterrcnn_resnet50_fpn_v2, FasterRCNN_ResNet50_FPN_V2_Weights, \"faster_rcnn_resnet_v2\", (255,127,0)),\n",
    "    DetectionModel(\"FasterRCNN\", \"mobilenet_v3_large_fpn\", fasterrcnn_mobilenet_v3_large_fpn, FasterRCNN_MobileNet_V3_Large_FPN_Weights, \"faster_rcnn_mobilenet_v3\", (191,255,0)),\n",
    "    DetectionModel(\"FasterRCNN\", \"mobilenet_v3_large_320_fpn\", fasterrcnn_mobilenet_v3_large_320_fpn, FasterRCNN_MobileNet_V3_Large_320_FPN_Weights, \"faster_rcnn_mobilenet_v3_320\", (0,149,255)),\n",
    "    DetectionModel(\"MaskRCNN\", \"resnet50_fpn\", maskrcnn_resnet50_fpn, MaskRCNN_ResNet50_FPN_Weights, \"mask_rcnn_resnet\", (255,0,170)),\n",
    "    DetectionModel(\"MaskRCNN\", \"resnet50_fpn_v2\", maskrcnn_resnet50_fpn_v2, MaskRCNN_ResNet50_FPN_V2_Weights, \"mask_rcnn_resnet_v2\", (255,212,0)),\n",
    "    DetectionModel(\"SSD300\", \"vgg16\", ssd300_vgg16, SSD300_VGG16_Weights, \"ssd_vgg16\", (106,255,0)),\n",
    "    DetectionModel(\"SSDLite320\", \"mobilenet_v3_large\", ssdlite320_mobilenet_v3_large, SSDLite320_MobileNet_V3_Large_Weights, \"ssd_mobilenet_v3\", (0,64,255)),\n",
    "    DetectionModel(\"YOLO\", \"csp_darknet53\", YOLO, 'yolov5nu.pt', \"yolov5nu\", (237,185,185)),\n",
    "    DetectionModel(\"YOLO\", \"csp_darknet53\", YOLO, 'yolov5su.pt', \"yolov5su\", (185,215,237)),\n",
    "    DetectionModel(\"YOLO\", \"csp_darknet53\", YOLO, 'yolov5mu.pt', \"yolov5mu\", (231,233,185)),\n",
    "    DetectionModel(\"YOLO\", \"csp_darknet53\", YOLO, 'yolov5lu.pt', \"yolov5lu\", (220,185,237)),\n",
    "    DetectionModel(\"YOLO\", \"csp_darknet53\", YOLO, 'yolov5xu.pt', \"yolov5xu\", (185,237,224)),\n",
    "    DetectionModel(\"YOLO\", \"csp_darknet53\", YOLO, 'yolov5n6u.pt', \"yolov5n6u\", (237,185,185)),\n",
    "    DetectionModel(\"YOLO\", \"csp_darknet53\", YOLO, 'yolov5s6u.pt', \"yolov5s6u\", (170,0,255)),\n",
    "    DetectionModel(\"YOLO\", \"csp_darknet53\", YOLO, 'yolov5m6u.pt', \"yolov5m6u\", (143,106,35)),\n",
    "    DetectionModel(\"YOLO\", \"csp_darknet53\", YOLO, 'yolov5l6u.pt', \"yolov5l6u\", (107,35,143)),\n",
    "    DetectionModel(\"YOLO\", \"csp_darknet53\", YOLO, 'yolov5x6u.pt', \"yolov5x6u\", (237,185,185)),\n",
    "    DetectionModel(\"YOLO\", \"csp_darknet53\", YOLO, 'yolov8n.pt', \"yolov8n\", (185,237,224)),\n",
    "    DetectionModel(\"YOLO\", \"csp_darknet53\", YOLO, 'yolov8s.pt', \"yolov8s\", (237,185,185)),\n",
    "    DetectionModel(\"YOLO\", \"csp_darknet53\", YOLO, 'yolov8m.pt', \"yolov8m\", (255,255,0)),\n",
    "    DetectionModel(\"YOLO\", \"csp_darknet53\", YOLO, 'yolov8l.pt', \"yolov8l\", (255,0,0)),\n",
    "    DetectionModel(\"YOLO\", \"csp_darknet53\", YOLO, 'yolov8x.pt', \"yolov8x\", (255,255,0)),\n",
    "    # DetectionModel(\"YOLO\", \"csp_darknet53\", YOLO, 'yolov9t.pt', \"yolov9t\", (220,185,237)),\n",
    "    # DetectionModel(\"YOLO\", \"csp_darknet53\", YOLO, 'yolov9s.pt', \"yolov9s\", (185,215,237)),\n",
    "    # DetectionModel(\"YOLO\", \"csp_darknet53\", YOLO, 'yolov9m.pt', \"yolov9m\", (237,185,185)),\n",
    "    DetectionModel(\"YOLO\", \"csp_darknet53\", YOLO, 'yolov9c.pt', \"yolov9c\", (0,234,255)),\n",
    "    DetectionModel(\"YOLO\", \"csp_darknet53\", YOLO, 'yolov9e.pt', \"yolov9e\", (170,0,255))#,\n",
    "    # DetectionModel(\"YOLO\", \"csp_darknet53\", YOLO, 'yolov10n.pt', \"yolov10n\", (185,237,224)),\n",
    "    # DetectionModel(\"YOLO\", \"csp_darknet53\", YOLO, 'yolov10s.pt', \"yolov10s\", (237,185,185)),\n",
    "    # DetectionModel(\"YOLO\", \"csp_darknet53\", YOLO, 'yolov10m.pt', \"yolov10m\", (255,255,0)),\n",
    "    # DetectionModel(\"YOLO\", \"csp_darknet53\", YOLO, 'yolov10b.pt', \"yolov10b\", (220,185,237)),\n",
    "    # DetectionModel(\"YOLO\", \"csp_darknet53\", YOLO, 'yolov10l.pt', \"yolov10l\", (255,0,0)),\n",
    "    # DetectionModel(\"YOLO\", \"csp_darknet53\", YOLO, 'yolov10x.pt', \"yolov10x\", (255,255,0))\n",
    "]\n",
    "print(\"Successfully initialized (and imported) vehicle detectors!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de333801-abd4-41bd-9a41-6d50ca7baad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initialized plate detectors!\n"
     ]
    }
   ],
   "source": [
    "# Plate detection models\n",
    "PLATE_DETECTION_MODELS = [\n",
    "    DetectionModel(\"YOLO\", \"csp_darknet53\", YOLO, \"best_plate_model.pt\", \"best_plate_model\", (220,185,237), True),\n",
    "    DetectionModel(\"YOLO\", \"csp_darknet53\", YOLO, \"vehicle_license_best.pt\", \"vehicle_license_best\", (170,0,255), True),\n",
    "    DetectionModel(\"YOLO\", \"csp_darknet53\", YOLO, \"best_3.pt\", \"best_3\", (185,237,224), True),\n",
    "    DetectionModel(\"YOLO\", \"csp_darknet53\", YOLO, \"best_4.pt\", \"best_4\", (220,185,237), True),\n",
    "    DetectionModel(\"YOLO\", \"csp_darknet53\", YOLO, \"best_5.pt\", \"best_5\", (185,215,237), True)\n",
    "]\n",
    "for i in range(len(PLATE_DETECTION_MODELS)):\n",
    "    if PLATE_DETECTION_MODELS[i].custom==True and os.path.isfile(PLATE_DETECTION_MODELS[i].weights):\n",
    "        PLATE_DETECTION_MODELS[i].model = PLATE_DETECTION_MODELS[i].model(PLATE_DETECTION_MODELS[i].weights)\n",
    "print(\"Successfully initialized plate detectors!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "452467d5-7591-4d53-a5d4-574b8e1bc4cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initialized plate recognizers!\n"
     ]
    }
   ],
   "source": [
    "# Plate text models\n",
    "PLATE_RECOGNITION_MODELS = [\n",
    "    DetectionModel(\"YOLO\", \"csp_darknet53\", YOLO, \"plate_char/yolov8x/weights/best.pt\", \"plate_char\", (220,185,237), True),\n",
    "    DetectionModel(\"YOLO\", \"csp_darknet53\", YOLO, \"charenyeni/yolov8x/weights/best.pt\", \"charenyeni\", (185,237,224), True),\n",
    "    DetectionModel(\"OCR\", \"tesseract\", pytesseract, \"\", \"pytesseract\", (220,185,237), True),\n",
    "    DetectionModel(\"OCR\", \"easyocr\", reader, \"\", \"easyocr\", (220,185,237), True)\n",
    "]\n",
    "for i in range(len(PLATE_RECOGNITION_MODELS)):\n",
    "    if PLATE_RECOGNITION_MODELS[i].custom==True and os.path.isfile(PLATE_RECOGNITION_MODELS[i].weights):\n",
    "        PLATE_RECOGNITION_MODELS[i].model = PLATE_RECOGNITION_MODELS[i].model(PLATE_RECOGNITION_MODELS[i].weights)\n",
    "print(\"Successfully initialized plate recognizers!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27438722-c9c1-4b9c-b684-d65a95ceece8",
   "metadata": {},
   "source": [
    "# Recognize License Plates Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c36b751-a17e-4d88-bae1-e0245a1825f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get grayscale image\n",
    "def grayscale(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# otsu thresholding\n",
    "def threshold(image):\n",
    "    return cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5a5beca-fd05-4721-9ce2-66484b9f4579",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_plates(i, j, k, processed_frame, detection_plate, detection):\n",
    "    currentModel = VEHICLE_DETECTION_MODELS[i]\n",
    "    currentPlateModel = PLATE_DETECTION_MODELS[j]\n",
    "    currentTextModel = PLATE_RECOGNITION_MODELS[k]\n",
    "    \n",
    "    x1, y1, x2, y2 = [int(x) for x in detection[0]]\n",
    "    a1, b1, a2, b2 = [int(x) for x in detection_plate[0]]\n",
    "\n",
    "    frame = processed_frame.copy()\n",
    "    license_frame = frame[y1+b1:y1+b2,x1+a1:x1+a2]\n",
    "\n",
    "    final_text = \"\"\n",
    "    final_precision = 0.0\n",
    "    final_speed = 0.0\n",
    "\n",
    "    if currentTextModel.concept==\"OCR\":\n",
    "        preprocessed_frame = threshold(grayscale(license_frame))\n",
    "\n",
    "        if currentTextModel.reference==\"pytesseract\":\n",
    "            start_time = time.time()\n",
    "            results = currentTextModel.model.image_to_data(preprocessed_frame, config='-c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789')\n",
    "            final_speed = time.time() - start_time\n",
    "\n",
    "            parsedLines = results.split('\\n')\n",
    "            best_depth = len(parsedLines)-2\n",
    "            for line in parsedLines:\n",
    "                params = line.split()\n",
    "                if len(params)==12 and float(params[10].replace('conf','0.0'))>=final_precision:\n",
    "                    final_precision = float(params[10].replace('conf','0.0'))\n",
    "                    final_text = params[11] if params[11]!=\"text\" else \"-\"\n",
    "\n",
    "            cv2.putText(frame, '{} ({:.3f}s) {} {:.2f}%'.format(final_text, final_speed, currentTextModel.reference, final_precision),(x1+a1+10,y1+b2+25),0,0.8,currentTextModel.color,1)\n",
    "            cv2.putText(frame, '{} ({:.3f}s) {:.2f}%'.format(final_text, final_speed+detection_plate[3]+detection[3], (final_precision+detection_plate[2]+detection[2])/3),(x1+10,y2+25),0,0.9,currentModel.color,2)\n",
    "        elif currentTextModel.reference==\"easyocr\":\n",
    "            start_time = time.time()\n",
    "            result = currentTextModel.model.readtext(preprocessed_frame)\n",
    "            final_speed = time.time() - start_time\n",
    "            for res in result:\n",
    "                if res[2]*100>final_precision:\n",
    "                    final_precision = res[2]*100\n",
    "                    final_text = res[1]\n",
    "                    \n",
    "            cv2.putText(frame, '{} ({:.3f}s) {} {:.2f}%'.format(final_text, final_speed, currentTextModel.reference, final_precision),(x1+a1+10,y1+b2+25),0,0.8,currentTextModel.color,1)\n",
    "    else:\n",
    "        plate_parts=[]\n",
    "        plate_text=\"\"\n",
    "        avg_conf = 0.0\n",
    "    \n",
    "        start_time = time.time()\n",
    "        results = currentTextModel.model(license_frame, agnostic_nms=True, verbose=False, device=device)[0]\n",
    "        final_speed = time.time() - start_time\n",
    "\n",
    "        counter = 0\n",
    "        for result in results:\n",
    "            detection_count = result.boxes.shape[0]\n",
    "            for i in range(detection_count):\n",
    "                cls = int(result.boxes.cls[i].item())\n",
    "                name = result.names[cls]\n",
    "                confidence = float(result.boxes.conf[i].item())\n",
    "                bounding_box = result.boxes.xyxy[i].cpu().numpy()\n",
    "                m1, n1, m2, n2 = [int(x) for x in bounding_box]\n",
    "                # Ensure m1 < m2 and n1 < n2\n",
    "                m1, m2 = min(m1, m2), max(m1, m2)\n",
    "                n1, n2 = min(n1, n2), max(n1, n2)\n",
    "                if confidence>currentModel.confidence_threshold_plate:\n",
    "                    plate_parts.append([m1,n1,name,confidence])\n",
    "                    cv2.rectangle(frame,(x1+a1+m1,y1+b1+n1),(x1+a1+m2,y1+b1+n2),currentTextModel.color,1)\n",
    "                    cv2.putText(frame, '{}'.format(name),(x1+a1+m1-20,y1+b1+n2+25),0,0.9,currentTextModel.color,1)\n",
    "                    # cv2.putText(frame, '{:.2f}%'.format(confidence*100),(x1+a1+m1,y1+b1+n1-100-15*counter),0,0.7,currentTextModel.color,1)\n",
    "                    counter+=1\n",
    "\n",
    "        sum_confidence = 0.0\n",
    "        if len(plate_parts)>0:\n",
    "            sorted_list = sorted(plate_parts,key=lambda l:l[0])\n",
    "            for part in range(len(sorted_list)):\n",
    "                if sorted_list[part][2]!=\"undefined\":\n",
    "                    plate_text+=sorted_list[part][2]\n",
    "                    sum_confidence += sorted_list[part][3]\n",
    "            final_precision = sum_confidence / len(sorted_list) * 100 if len(sorted_list)>0 else 0.0\n",
    "            final_text = plate_text\n",
    "\n",
    "        cv2.putText(frame, '{} ({:.3f}s) {} {:.2f}%'.format(final_text, final_speed, currentTextModel.reference, final_precision),(x1+a1+10,y1+b2+35),0,0.8,currentTextModel.color,1)\n",
    "\n",
    "    # Add result to the statistics\n",
    "    VEHICLE_DETECTION_MODELS[i].addPlateRecognition(DetectionResult(model=currentTextModel.reference, label=final_text, precision=final_precision, \n",
    "                                                                    speed=final_speed, device=detection_plate[4], source=detection_plate[5], \n",
    "                                                                    frame=detection_plate[6], id=f'{detection[6]}{i}{j}{k}', boundingBox=None, \n",
    "                                                                    details=f'Pipeline Speed: {final_speed+detection_plate[3]+detection[3]:.5f}s'))\n",
    "    \n",
    "    cv2.putText(frame, '{} ({:.3f}s) {:.2f}%'.format(final_text, final_speed+detection_plate[3]+detection[3], (final_precision+detection_plate[2]+detection[2])/3),(x1+10,y2+25),0,0.9,currentModel.color,2)\n",
    "\n",
    "    # Outputs frames as a smooth video and does not allow prints\n",
    "    _, display_frame = cv2.imencode('.jpeg', frame)\n",
    "    display_handle.update(IPython.display.Image(data=display_frame.tobytes()))\n",
    "    IPython.display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "969c09c9-2b07-4d5d-99af-002a1707fc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_plate_recognition(i, j, processed_frame, detection_plate, detection):\n",
    "    if VEHICLE_DETECTION_MODELS[i].textModel>-1:\n",
    "        recognize_plates(i, j, VEHICLE_DETECTION_MODELS[i].textModel, processed_frame, detection_plate, detection)\n",
    "    else:\n",
    "        for k in range(len(PLATE_RECOGNITION_MODELS)):\n",
    "            recognize_plates(i, j, k, processed_frame, detection_plate, detection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5094cf4e-95ab-42cc-811d-fa58fc72cef5",
   "metadata": {},
   "source": [
    "# Detect License Plates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "617db7d4-2537-426b-a26b-c87ef74e2747",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_plates(i, j, processed_frame, detection):\n",
    "    currentModel = VEHICLE_DETECTION_MODELS[i]\n",
    "    currentPlateModel = PLATE_DETECTION_MODELS[j]\n",
    "\n",
    "    frame = processed_frame.copy()\n",
    "    \n",
    "    x1, y1, x2, y2 = [int(x) for x in detection[0]]\n",
    "    vehicle_frame = frame[y1:y2,x1:x2]\n",
    "    \n",
    "    start_time = time.time()\n",
    "    results = currentPlateModel.model(vehicle_frame, agnostic_nms=True, verbose=False, device=device)[0]\n",
    "    processing_time = time.time() - start_time \n",
    "    for result in results:\n",
    "        detection_count = result.boxes.shape[0]\n",
    "        for k in range(detection_count):\n",
    "            cls = int(result.boxes.cls[k].item())\n",
    "            name = result.names[cls]\n",
    "            confidence = float(result.boxes.conf[k].item())\n",
    "            bounding_box = result.boxes.xyxy[k].cpu().numpy()\n",
    "\n",
    "            if confidence > currentModel.confidence_threshold_plate:\n",
    "                a1, b1, a2, b2 = [int(x) for x in bounding_box]\n",
    "                # Ensure a1 < a2 and b1 < b2\n",
    "                a1, a2 = min(a1, a2), max(a1, a2)\n",
    "                b1, b2 = min(b1, b2), max(b1, b2)\n",
    "\n",
    "                label_text = f'{currentPlateModel.reference} ({processing_time:.3f}s) {confidence*100:.2f}% {name.upper()}'\n",
    "                \n",
    "                cv2.rectangle(frame, (x1+a1, y1+b1), (x1+a2, y1+b2),currentPlateModel.color,1)\n",
    "                cv2.putText(frame, label_text,(x1+a1-10,y1+b1-15),0,0.8,currentPlateModel.color,1)\n",
    "\n",
    "                # Add result to the statistics\n",
    "                detection_plate = [bounding_box, name, confidence*100, processing_time, detection[4], detection[5], detection[6]]\n",
    "                VEHICLE_DETECTION_MODELS[i].addPlateDetection(DetectionResult(model=currentPlateModel.reference, label=detection_plate[1], precision=detection_plate[2], \n",
    "                                                                              speed=detection_plate[3], device=detection_plate[4], source=detection_plate[5], \n",
    "                                                                              frame=detection[6], id=f'{detection[6]}{i}{j}', boundingBox=detection[0], \n",
    "                                                                              details=label_text))\n",
    "\n",
    "                # Outputs frames as a smooth video and does not allow prints\n",
    "                _, display_frame = cv2.imencode('.jpeg', frame)\n",
    "                display_handle.update(IPython.display.Image(data=display_frame.tobytes()))\n",
    "                IPython.display.clear_output(wait=True)\n",
    "                \n",
    "                prepare_plate_recognition(i, j, frame, detection_plate, detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9be9002-0682-4234-9e2f-d5c6b8e1d281",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_plate_detection(i, processed_frame, detection):\n",
    "    if VEHICLE_DETECTION_MODELS[i].plateModel>-1:\n",
    "        detect_plates(i, VEHICLE_DETECTION_MODELS[i].plateModel, processed_frame, detection)\n",
    "    else:\n",
    "        for j in range(len(PLATE_DETECTION_MODELS)):\n",
    "            detect_plates(i, j, processed_frame, detection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550af53f-722a-4f66-9404-2064463800d6",
   "metadata": {},
   "source": [
    "# Detect vehicles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef189f3d-8146-499b-a5df-53b8b72d36e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_vehicle_detection(i, processed_frame, detection):\n",
    "    currentModel = VEHICLE_DETECTION_MODELS[i]\n",
    "    \n",
    "    # Extract bounding boxes\n",
    "    x1, y1, x2, y2 = [int(x) for x in detection[0]]\n",
    "\n",
    "    # Ensure x1 < x2 and y1 < y2\n",
    "    x1, x2 = min(x1, x2), max(x1, x2)\n",
    "    y1, y2 = min(y1, y2), max(y1, y2)\n",
    "\n",
    "    # Build up the label text out of class name, confidence score and inference speed\n",
    "    label_text = '{} ({:.3f}s) {:.2f}% {}'.format(currentModel.reference, detection[3], detection[2], detection[1].upper())\n",
    "\n",
    "    # Add result to the statistics\n",
    "    VEHICLE_DETECTION_MODELS[i].addDetection(DetectionResult(model=currentModel.reference, label=detection[1], precision=detection[2], \n",
    "                                                             speed=detection[3], device=detection[4], source=detection[5], \n",
    "                                                             frame=detection[6], id=f'{detection[6]}{i}', boundingBox=detection[0], \n",
    "                                                             details=label_text))\n",
    "\n",
    "    # Draw bounding boxes and label on the frame\n",
    "    cv2.rectangle(processed_frame, (x1, y1), (x2, y2), currentModel.color, 1)\n",
    "    cv2.putText(processed_frame, label_text, (x1+5, y1+20), 0, 0.7, currentModel.color, 1)\n",
    "\n",
    "    # Display the results on the image\n",
    "    _, display_frame = cv2.imencode('.jpeg', processed_frame)\n",
    "    display_handle.update(IPython.display.Image(data=display_frame.tobytes()))\n",
    "    IPython.display.clear_output(wait=True)\n",
    "\n",
    "    # For further processing of a detected vehicle object\n",
    "    prepare_plate_detection(i, processed_frame, detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "deb2ec92-0381-42a9-a35e-8ae7df0abf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_vehicles(i, plateModel, textModel, frame, frameIndex=-1, source=None, confidence_threshold=0.5, confidence_threshold_plate=0.3):\n",
    "    # Define current model\n",
    "    VEHICLE_DETECTION_MODELS[i].plateModel = plateModel\n",
    "    VEHICLE_DETECTION_MODELS[i].textModel = textModel\n",
    "    VEHICLE_DETECTION_MODELS[i].confidence_threshold = confidence_threshold\n",
    "    VEHICLE_DETECTION_MODELS[i].confidence_threshold_plate = confidence_threshold_plate\n",
    "    currentModel = VEHICLE_DETECTION_MODELS[i]\n",
    "\n",
    "    if currentModel.custom==False or (currentModel.custom==True and os.path.isfile(currentModel.weights)):\n",
    "    \n",
    "        # Keep original input intact to avoid different models outputs being accumulately overwritten\n",
    "        processed_frame = frame.copy()\n",
    "    \n",
    "        if currentModel.concept==\"YOLO\":\n",
    "            # Handle a YOLO model object detection\n",
    "            start_time = time.time()\n",
    "            results = currentModel.model(processed_frame, agnostic_nms=True, verbose=False, device=device)[0]\n",
    "            processing_time = time.time() - start_time\n",
    "    \n",
    "            # Iterate through results\n",
    "            for result in results:\n",
    "                detection_count = result.boxes.shape[0]\n",
    "    \n",
    "                # Iterate through all detections\n",
    "                for j in range(detection_count):\n",
    "                    cls = int(result.boxes.cls[j].item())\n",
    "                    name = result.names[cls] # Extract class name\n",
    "                    confidence = float(result.boxes.conf[j].item()) # Extract confidence score\n",
    "                    bounding_box = result.boxes.xyxy[j].cpu().numpy() # Extract bounding boxes\n",
    "                    \n",
    "                    # Vehicle detected, proceed\n",
    "                    if name in target_classes and confidence>confidence_threshold:\n",
    "                        detection = [bounding_box, name, confidence*100, processing_time, device, source, frameIndex]\n",
    "                        handle_vehicle_detection(i, processed_frame, detection)\n",
    "        else:\n",
    "            # Handle a Pytorch model\n",
    "            \n",
    "            # Preprocessing: Convert frame to RGB and PIL Image, then apply transformation\n",
    "            frame_rgb = cv2.cvtColor(processed_frame, cv2.COLOR_BGR2RGB)\n",
    "            pil_image = Image.fromarray(frame_rgb)\n",
    "            image = transform(pil_image).unsqueeze(0).to(device)\n",
    "        \n",
    "            # Object detection\n",
    "            start_time = time.time()\n",
    "            with torch.no_grad():\n",
    "                predictions = currentModel.model(image)\n",
    "        \n",
    "            # Processing (inference) time\n",
    "            processing_time = time.time() - start_time\n",
    "            \n",
    "            # Visualization\n",
    "            scores = predictions[0]['scores']\n",
    "            boxes = predictions[0]['boxes']\n",
    "            labels = predictions[0]['labels']\n",
    "            \n",
    "            # For each detection\n",
    "            for confidence, bounding_box, label in zip(scores, boxes, labels):\n",
    "                name = currentModel.weights.DEFAULT.meta[\"categories\"][label.item()]\n",
    "                if name in target_classes and confidence>confidence_threshold:\n",
    "                    detection = [bounding_box, name, confidence*100, processing_time, device, source, frameIndex]\n",
    "                    handle_vehicle_detection(i, processed_frame, detection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ac25db-24bc-4f3b-a6fc-f6b4acbf307b",
   "metadata": {},
   "source": [
    "# Run The Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "127f8c42-0a94-4d92-9559-424258972996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source released.\n"
     ]
    }
   ],
   "source": [
    "# Parameters for input\n",
    "target_classes = [\"truck\", \"bus\", \"car\", \"train\", \"bicycle\"]\n",
    "\n",
    "videos = [\n",
    "    \"data/video/sample.MP4\", \n",
    "    \"data/video/vecteezy_car-and-truck-traffic-on-the-highway-in-europe-poland_7957364.MP4\", \n",
    "    \"data/video/2034115-hd_1920_1080_30fps.MP4\"\n",
    "]\n",
    "\n",
    "images = [\n",
    "    \"../samples/truck.jpg\"\n",
    "]\n",
    "\n",
    "inputType = \"video\"\n",
    "inputIndex = 0 # Which index in the input array?\n",
    "\n",
    "vehicleModel = -1 # Use a specific model for vehicle detection (Use index of the array)\n",
    "plateModel = -1 # Use a specific model for license plate detection\n",
    "textModel = -1 # Use a specific model for license plate recognition\n",
    "\n",
    "confidence_threshold = 0.5\n",
    "confidence_threshold_plate = 0.3\n",
    "every = 60\n",
    "safety_limit= 2000\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Transforms input image to tensor, the models usually automatically resize inputs based on the trained dataset resolution.\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "def handleFrame(frame, frameIndex=-1, source=None, confidence_threshold=0.5, confidence_threshold_plate=0.3):\n",
    "    if vehicleModel>-1:\n",
    "        detect_vehicles(vehicleModel, plateModel, textModel, frame, frameIndex, source, confidence_threshold, confidence_threshold_plate)\n",
    "    else:\n",
    "        for i in range(len(VEHICLE_DETECTION_MODELS)):\n",
    "            detect_vehicles(i, plateModel, textModel, frame, frameIndex, source, confidence_threshold, confidence_threshold_plate)\n",
    "\n",
    "def handleRelease():\n",
    "    cam.release()\n",
    "    print(\"Source released.\")\n",
    "\n",
    "source = videos[inputIndex] if inputType==\"video\" else images[inputIndex] if inputType==\"image\" else 0\n",
    "cam = cv2.VideoCapture(source) if inputType!=\"image\" else cv2.imread(source, cv2.IMREAD_COLOR)\n",
    "display_handle=display(None, display_id=True)\n",
    "start = 0 if inputType==\"video\" else -1\n",
    "end = int(cam.get(cv2.CAP_PROP_FRAME_COUNT)) if inputType==\"video\" else -1\n",
    "if inputType==\"video\": cam.set(1, start)\n",
    "frameCount=start\n",
    "while_safety=0\n",
    "\n",
    "if inputType==\"image\":\n",
    "    handleFrame(cam, frameCount, source, confidence_threshold, confidence_threshold_plate)\n",
    "else:\n",
    "    if not cam.isOpened(): print(\"Error: Could not open source.\")\n",
    "    else:\n",
    "        try:\n",
    "            while True if end<0 else frameCount<end:\n",
    "                _, frame = cam.read()\n",
    "                if frame is None:\n",
    "                    if source!=0:\n",
    "                        if while_safety > safety_limit: break\n",
    "                        while_safety += 1\n",
    "                        continue\n",
    "                    else:\n",
    "                        print(\"Error: Could not capture frame.\")\n",
    "                        cam.release()\n",
    "                        break\n",
    "                        \n",
    "                if every>0:\n",
    "                    if (frameCount+1)%math.floor(every) == 0:\n",
    "                        while_safety = 0\n",
    "                        handleFrame(frame, frameCount, source, confidence_threshold, confidence_threshold_plate)\n",
    "                else:\n",
    "                    while_safety=0\n",
    "                    handleFrame(frame, frameCount, source, confidence_threshold, confidence_threshold_plate)\n",
    "                frameCount += 1\n",
    "            handleRelease()\n",
    "        except KeyboardInterrupt:\n",
    "            handleRelease()\n",
    "        except:\n",
    "            print(\"Unknown error.\")\n",
    "            try:\n",
    "                cam.release()\n",
    "                raise TypeError(\"Error: Source could not be released.\")\n",
    "            except:\n",
    "                pass\n",
    "            traceback.print_exc() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c9ffa4-3c0a-48fe-acc1-ec9dd57ceaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "VEHICLE_DETECTION_MODELS[0].printResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef1d8e7-8aa4-42f3-be45-e96c28143884",
   "metadata": {},
   "outputs": [],
   "source": [
    "VEHICLE_DETECTION_MODELS[0].printDetections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2d4d44-7e3b-462e-86ce-3752dafb2eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "VEHICLE_DETECTION_MODELS[0].printPlateDetections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66d0f51-4d70-4fae-b3a4-ef53df35a809",
   "metadata": {},
   "outputs": [],
   "source": [
    "VEHICLE_DETECTION_MODELS[0].printPlateRecognitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf9026b-555a-43b1-a2d4-afde4dfac0e4",
   "metadata": {},
   "source": [
    "# Output handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5f4648-acd0-4801-a21b-9ec4cc60ed7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The output of the experiment result is processed below\n",
    "print()\n",
    "print(device)\n",
    "print(source)\n",
    "print()\n",
    "\n",
    "BestPrecision=None\n",
    "BestAvgPrecision=None\n",
    "WorstPrecision=None\n",
    "BestSpeed=None\n",
    "BestAvgSpeed=None\n",
    "WorstSpeed=None\n",
    "\n",
    "Models=[]\n",
    "BestPrecisions=[]\n",
    "AvgPrecisions=[]\n",
    "WorstPrecisions=[]\n",
    "BestInferenceSpeeds=[]\n",
    "AvgInferenceSpeeds=[]\n",
    "WorstInferenceSpeeds=[]\n",
    "TotalDetectionsArr=[]\n",
    "TotalInferencesArr=[]\n",
    "\n",
    "for i in range(len(VEHICLE_DETECTION_MODELS)):\n",
    "    currentModel = VEHICLE_DETECTION_MODELS[i]\n",
    "    \n",
    "    # You can uncomment this to see details of every model\n",
    "    # currentModel.printResults()\n",
    "\n",
    "    Models.append(currentModel.reference)\n",
    "    BestPrecisions.append(currentModel.getMaxPrecision())\n",
    "    AvgPrecisions.append(currentModel.getAveragePrecision())\n",
    "    WorstPrecisions.append(currentModel.getMinPrecision())\n",
    "    BestInferenceSpeeds.append(currentModel.getMinInferenceSpeed())\n",
    "    AvgInferenceSpeeds.append(currentModel.getAverageInferenceSpeed())\n",
    "    WorstInferenceSpeeds.append(currentModel.getMaxInferenceSpeed())\n",
    "    TotalDetectionsArr.append(currentModel.detectionsCount())\n",
    "    TotalInferencesArr.append(currentModel.inferencesCount())\n",
    "    \n",
    "    if BestPrecision is None or BestPrecision.getMaxPrecision()<=currentModel.getMaxPrecision():\n",
    "        BestPrecision = currentModel\n",
    "    if BestAvgPrecision is None or BestAvgPrecision.getAveragePrecision()<=currentModel.getAveragePrecision():\n",
    "        BestAvgPrecision = currentModel\n",
    "    if WorstPrecision is None or WorstPrecision.getMinPrecision()>=currentModel.getMinPrecision():\n",
    "        WorstPrecision = currentModel\n",
    "    if BestSpeed is None or BestSpeed.getMinInferenceSpeed()>=currentModel.getMinInferenceSpeed():\n",
    "        BestSpeed = currentModel\n",
    "    if BestAvgSpeed is None or BestAvgSpeed.getAverageInferenceSpeed()>=currentModel.getAverageInferenceSpeed():\n",
    "        BestAvgSpeed = currentModel\n",
    "    if WorstSpeed is None or WorstSpeed.getMaxInferenceSpeed()<=currentModel.getMaxInferenceSpeed():\n",
    "        WorstSpeed = currentModel\n",
    "        \n",
    "if BestPrecision is not None: \n",
    "    print(\"Best Precision:\")\n",
    "    BestPrecision.printResults()\n",
    "if BestAvgPrecision is not None: \n",
    "    print(\"Best Average Precision:\")\n",
    "    BestAvgPrecision.printResults()\n",
    "if WorstPrecision is not None: \n",
    "    print(\"Worst Precision:\")\n",
    "    WorstPrecision.printResults()\n",
    "if BestSpeed is not None: \n",
    "    print(\"Best Speed:\")\n",
    "    BestSpeed.printResults()\n",
    "if BestAvgSpeed is not None: \n",
    "    print(\"Best Average Speed:\")\n",
    "    BestAvgSpeed.printResults()\n",
    "if WorstSpeed is not None: \n",
    "    print(\"Worst Speed:\")\n",
    "    WorstSpeed.printResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1747c77e-ea14-4321-9cd4-7b024bda8f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This can be executed then the output is copied and used to represent the data as diagrams and tables\n",
    "print(\"models=\",Models)\n",
    "print(\"best_precisions=\",BestPrecisions)\n",
    "print(\"avg_precisions=\",AvgPrecisions)\n",
    "print(\"worst_precisions=\",WorstPrecisions)\n",
    "print(\"best_inference_speeds=\",BestInferenceSpeeds)\n",
    "print(\"avg_inference_speeds=\",AvgInferenceSpeeds)\n",
    "print(\"worst_inference_speeds=\",WorstInferenceSpeeds)\n",
    "print(\"total_detections=\",TotalDetectionsArr)\n",
    "print(\"total_inferences=\",TotalInferencesArr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010ebc73-1f6e-42ec-85b5-6dd111692f19",
   "metadata": {},
   "source": [
    "# After we copy the output from the Detection Experiment Analysis, we can run it in another cell, then use the code below to save and display the data. I still wanted to make the primary data also part of the output from the previous code, like the device used, source input path and parameters like framerate, threshold and target classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c043144-7d4f-49e7-b715-cbed0dd21c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can paste the array definitions from the output above in this cell and run it\n",
    "models= ['fcos_resnet', 'retinanet_resnet', 'retinanet_resnet_v2', 'faster_rcnn_resnet', 'faster_rcnn_resnet_v2', 'faster_rcnn_mobilenet_v3', 'faster_rcnn_mobilenet_v3_320', 'mask_rcnn_resnet', 'mask_rcnn_resnet_v2', 'ssd_vgg16', 'ssd_mobilenet_v3', 'yolov5nu', 'yolov5su', 'yolov5mu', 'yolov5lu', 'yolov5xu', 'yolov5n6u', 'yolov5s6u', 'yolov5m6u', 'yolov5l6u', 'yolov5x6u', 'yolov8n', 'yolov8s', 'yolov8m', 'yolov8l', 'yolov8x', 'yolov9c', 'yolov9e']\n",
    "best_precisions= [64.07835388183594, 0.0, 55.489200592041016, 95.16394805908203, 98.24671173095703, 89.18415069580078, 95.50997924804688, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "avg_precisions= [61.71642875671387, 0.0, 54.490304946899414, 74.99663543701172, 98.24671173095703, 89.18415069580078, 95.50997924804688, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "worst_precisions= [59.3545036315918, 0.0, 53.49140930175781, 54.829322814941406, 98.24671173095703, 89.18415069580078, 95.50997924804688, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "best_inference_speeds= [1.9180281162261963, 0.0, 1.7949974536895752, 1.5070006847381592, 2.358997344970703, 0.44583773612976074, 0.20199799537658691, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "avg_inference_speeds= [1.9180281162261963, 0.0, 1.7949974536895752, 1.5070006847381592, 2.358997344970703, 0.44583773612976074, 0.20199799537658691, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "worst_inference_speeds= [1.9180281162261963, 0.0, 1.7949974536895752, 1.5070006847381592, 2.358997344970703, 0.44583773612976074, 0.20199799537658691, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "total_detections= [2, 0, 2, 2, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "total_inferences= [1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebaf7a9-4c1d-454c-92a9-2a969dccc1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "# Generate a color map\n",
    "num_models = len(models)\n",
    "cmap = matplotlib.colormaps.get_cmap('nipy_spectral')\n",
    "colors = [cmap(i / num_models) for i in range(num_models)]\n",
    "\n",
    "# Create a figure and plot with unique colors\n",
    "plt.figure(figsize=(14, 10))\n",
    "for i, model in enumerate(models):\n",
    "    plt.scatter(avg_inference_speeds[i], avg_precisions[i], color=colors[i], label=model, edgecolor='black')\n",
    "\n",
    "print(\"DEVICE:\", device)\n",
    "print(\"SOURCE:\", source)\n",
    "print(\"SKIP EVERY\", every, \"FRAMES\")\n",
    "print(\"TOTALLY PROCESSED FRAMES:\", max(total_inferences))\n",
    "print(\"COCO Dataset, Classes:\", target_classes)\n",
    "print(\"THRESHOLD:\", confidence_threshold*100, \"%\")\n",
    "# Axis labels and plot title\n",
    "plt.xlabel('Average Speed (seconds)')\n",
    "plt.ylabel('Average Precision (%)')\n",
    "plt.title('Model Performance: Average Inference Speed x Average Accuracy')\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1.05, 1), fontsize='small')\n",
    "plt.grid(True)\n",
    "# plt.savefig(\"Experiment1_Diagram.png\", bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Set up the figure and axis for the table\n",
    "fig, ax = plt.subplots(figsize=(14, 12))  # Adjust size as needed\n",
    "ax.axis('tight')\n",
    "ax.axis('off')\n",
    "\n",
    "# The table data: transpose the array to make each column a different metric\n",
    "table_data = np.transpose([models, best_precisions, avg_precisions, worst_precisions])\n",
    "\n",
    "# Create the table in the plot\n",
    "table = ax.table(cellText=table_data, colLabels=[\"Model\", \"Best Precision (%)\", \"Average Precision (%)\", \"Worst Precision (%)\"],\n",
    "                 cellLoc='center', loc='center', colColours=[\"palegreen\"] * 4)\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(10)\n",
    "table.scale(1.2, 1.2)  # Scale table size\n",
    "\n",
    "plt.title(\"Model Precision Metrics\")\n",
    "# plt.savefig(\"Experiment1_Precision_Table.png\", bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Set up the figure and axis for the table\n",
    "fig, ax = plt.subplots(figsize=(14, 12))  # Adjust size as needed\n",
    "ax.axis('tight')\n",
    "ax.axis('off')\n",
    "\n",
    "# The table data: transpose the array to make each column a different metric\n",
    "table_data = np.transpose([models, best_inference_speeds, avg_inference_speeds, worst_inference_speeds])\n",
    "\n",
    "# Create the table in the plot\n",
    "table = ax.table(cellText=table_data, colLabels=[\"Model\", \"Best Inference Speed (s)\", \"Average Inference Speed (s)\", \"Worst Inference Speed (s)\"],\n",
    "                 cellLoc='center', loc='center', colColours=[\"palegreen\"] * 4)\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(10)\n",
    "table.scale(1.2, 1.2)  # Scale table size\n",
    "\n",
    "plt.title(\"Model Inference Speed Metrics\")\n",
    "# plt.savefig(\"Experiment1_Time_Table.png\", bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# This code is used to remap the data as a latex table sorted by average precision in descending order.\n",
    "data = []\n",
    "for i in range(len(models)):\n",
    "    data.append([models[i], f'{avg_precisions[i]:.2f}', f'{avg_inference_speeds[i]:.5f}'])\n",
    "\n",
    "# LaTeX model names mapping\n",
    "latex_model_names = {\n",
    "    'fcos_resnet': 'FCOS ResNet50 FPN',\n",
    "    'retinanet_resnet': 'RetinaNet ResNet50 FPN',\n",
    "    'retinanet_resnet_v2': 'RetinaNet ResNet50 FPN V2',\n",
    "    'faster_rcnn_resnet': 'Faster R-CNN ResNet50 FPN',\n",
    "    'faster_rcnn_resnet_v2': 'Faster R-CNN ResNet50 FPN V2',\n",
    "    'faster_rcnn_mobilenet_v3': 'Faster R-CNN MobileNet V3 L',\n",
    "    'faster_rcnn_mobilenet_v3_320': 'Faster R-CNN MobileNet V3 L 320',\n",
    "    'mask_rcnn_resnet': 'Mask R-CNN ResNet50',\n",
    "    'mask_rcnn_resnet_v2': 'Mask R-CNN ResNet50 FPN V2',\n",
    "    'ssd_vgg16': 'SSD VGG16',\n",
    "    'ssd_mobilenet_v3': 'SSDLite MobileNet V3 Large',\n",
    "    'yolov5nu': 'YOLOv5nu',\n",
    "    'yolov5su': 'YOLOv5su',\n",
    "    'yolov5mu': 'YOLOv5mu',\n",
    "    'yolov5lu': 'YOLOv5lu',\n",
    "    'yolov5xu': 'YOLOv5xu',\n",
    "    'yolov5n6u': 'YOLOv5n6u',\n",
    "    'yolov5s6u': 'YOLOv5s6u',\n",
    "    'yolov5m6u': 'YOLOv5m6u',\n",
    "    'yolov5l6u': 'YOLOv5l6u',\n",
    "    'yolov5x6u': 'YOLOv5x6u',\n",
    "    'yolov8n': 'YOLOv8n',\n",
    "    'yolov8s': 'YOLOv8s',\n",
    "    'yolov8m': 'YOLOv8m',\n",
    "    'yolov8l': 'YOLOv8l',\n",
    "    'yolov8x': 'YOLOv8x',\n",
    "    'yolov9c': 'YOLOv9c',\n",
    "    'yolov9e': 'YOLOv9e'\n",
    "}\n",
    "\n",
    "# Sort data by average precision in descending order\n",
    "data_sorted = sorted(data, key=lambda x: float(x[1]), reverse=True)\n",
    "\n",
    "# Generate LaTeX table\n",
    "latex_table = \"\\\\begin{table}[H]\\n\\\\centering\\n\\\\begin{tabular}{lrr}\\n\\\\toprule\\n\"\n",
    "latex_table += \"\\\\multicolumn{3}{c}{A100 Experiment 1a: Vehicle Detection Models Performance}\\\\\\\\ \\\\cmidrule{1-3}\\n\"\n",
    "latex_table += \"Model & Average Precision (\\\\%) & Average Inference Speed (s)\\\\\\\\\\n\\\\midrule\\n\"\n",
    "\n",
    "best_prec_index = 0\n",
    "best_speed = [99999.99, 0]\n",
    "for i in range(len(data_sorted)):\n",
    "    if float(data_sorted[i][2])<best_speed[0]:\n",
    "        best_speed = [float(data_sorted[i][2]), i]\n",
    "\n",
    "count = 0\n",
    "for entry in data_sorted:\n",
    "    model = latex_model_names[entry[0]]\n",
    "    avg_precision = float(entry[1])\n",
    "    avg_speed = float(entry[2])\n",
    "\n",
    "    if count==best_prec_index:\n",
    "        if count==best_speed[1]:\n",
    "            latex_table += f\"\\\\textbf{{{model}}} & \\\\textbf{{{avg_precision:.2f}}} & \\\\textbf{{{avg_speed:.5f}}} \\\\\\\\ \\\\addlinespace\\n\"\n",
    "        else:\n",
    "            latex_table += f\"\\\\textbf{{{model}}} & \\\\textbf{{{avg_precision:.2f}}} & {avg_speed:.5f} \\\\\\\\ \\\\addlinespace\\n\"\n",
    "    else:\n",
    "        if count==best_speed[1]:\n",
    "            latex_table += f\"\\\\textbf{{{model}}} & {avg_precision:.2f} & \\\\textbf{{{avg_speed:.5f}}} \\\\\\\\ \\\\addlinespace\\n\"\n",
    "        else:\n",
    "            latex_table += f\"{model} & {avg_precision:.2f} & {avg_speed:.5f} \\\\\\\\ \\\\addlinespace\\n\"\n",
    "\n",
    "    count+=1\n",
    "\n",
    "latex_table += \"\\\\bottomrule\\n\\\\end{tabular}\\n\\\\caption{(DEVICE) Experiment (X)A: Vehicle Detection Models Performance}\\n\\\\label{table:Device_Experiment_1A_Vehicle_Detection_Performance}\\n\\\\end{table}\"\n",
    "\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53be9d06-188a-4653-bf9d-711987cdf762",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
