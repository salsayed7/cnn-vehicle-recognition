{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "61c10a6a-ecf0-4ba6-b82c-bcf6a642921a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source released.\n",
      "\n",
      "Detected Plates: \n",
      " [['65.81149101257324' 'BUS' '84.66718792915344' ... '0.0' '-' 'pytesseract']\n",
      " ['65.81149101257324' 'BUS' '84.66718792915344' ... '0.0' 'WAFSHW379' 'pytesseract']\n",
      " ['65.81149101257324' 'BUS' '84.66718792915344' ... '28.131838772282723' 'hh379' 'easyocr']\n",
      " ...\n",
      " ['84.02048945426941' 'TRUCK' '70.30436396598816' ... '0.0' '-' 'pytesseract']\n",
      " ['84.02048945426941' 'TRUCK' '70.30436396598816' ... '24.132578362115062' 'JyEcg' 'easyocr']\n",
      " ['84.02048945426941' 'TRUCK' '39.7539347410202' ... '0.0' '-' 'pytesseract']]\n",
      "\n",
      "Correctly Detected Plates: \n",
      " [['59.67785120010376' 'BUS' '82.01947212219238' 'LICENSE-PLATE' '60.83841044778365' 'HAFshk 379' 'easyocr']\n",
      " ['76.15963220596313' 'BUS' '83.02473425865173' 'LICENSE-PLATE' '62.22941007807742' 'KAFshH 379' 'easyocr']\n",
      " ['90.1332139968872' 'TRUCK' '80.19434213638306' 'LICENSE-PLATE' '64.08528222719607' 'IGH 3353A' 'easyocr']\n",
      " ['95.09167075157166' 'TRUCK' '81.67493343353271' 'LICENSE-PLATE' '60.094541549777524' 'S0' 'easyocr']]\n",
      "\n",
      "Better Detected Plates: \n",
      " []\n",
      "\n",
      "Best Detected Plate: \n",
      " [['95.09167075157166' 'TRUCK' '81.67493343353271' 'LICENSE-PLATE' '60.094541549777524' 'S0' 'easyocr']]\n",
      "\n",
      "Most Repeated Plates: \n",
      " [['95.09167075157166' 'TRUCK' '84.41890478134155' 'LICENSE-PLATE' '0.0' '-' 'pytesseract']]\n",
      "\n",
      "Best Repeated Plate: \n",
      " [['95.09167075157166' 'TRUCK' '84.41890478134155' 'LICENSE-PLATE' '0.0' '-' 'pytesseract']]\n",
      "times [['yolov8x', 'WAFHW379', 1.2789990901947021], ['yolov8x_charen', 'HAFHH379', 1.2267022132873535], 0.17499971389770508, ['pytesseract', 'WAFSHW379', 0.17499971389770508], ['easyocr', 'MAF', 0.17600011825561523], ['yolov8x', 'HAFHW379', 0.5850002765655518], ['yolov8x_charen', 'HAFHH379', 0.5399999618530273], 0.15799975395202637, ['pytesseract', 'HAFHW379', 0.15799975395202637], ['easyocr', 'MF4lE7)', 0.24199986457824707], ['yolov8x', 'WAFHW379', 0.5840001106262207], ['yolov8x_charen', 'HAFHH379', 0.5839996337890625], 0.18500018119812012, ['pytesseract', 'HAFHW379', 0.18500018119812012], ['easyocr', 'HFsHkB7)', 0.11799979209899902], ['yolov8x', 'WAFHW379', 0.6229400634765625], ['yolov8x_charen', 'MFHH379', 0.6069984436035156], 0.15593504905700684, ['pytesseract', 'WAFHW329', 0.15593504905700684], ['easyocr', 'HF;H1B79]', 0.19900250434875488], ['yolov8x', 'HAFHW379', 0.6100003719329834], ['yolov8x_charen', 'HAFHH379', 0.6099987030029297], 0.1569991111755371, ['pytesseract', 'HAFSHW379', 0.1569991111755371], ['easyocr', 'HFshk679]', 0.11800122261047363], ['yolov8x', 'WAFHW379', 0.5720000267028809], ['yolov8x_charen', 'MAFHH379', 0.5810000896453857], 0.16596341133117676, ['pytesseract', 'HAFSHW379', 0.16596341133117676], ['easyocr', 'HAF2hkB379]', 0.19800090789794922], ['yolov8x', 'WAFHW379', 0.41300106048583984], ['yolov8x_charen', 'MAFHH379', 0.43200063705444336], 0.16200041770935059, ['pytesseract', '-', 0.16200041770935059], ['easyocr', 'HHFeHH 379]', 0.13399910926818848], ['yolov8x', 'WAFHW379', 0.5019989013671875], ['yolov8x_charen', 'MAFHH379', 0.5480306148529053], 0.15400004386901855, ['pytesseract', '-', 0.15400004386901855], ['easyocr', 'KAFehk 379', 0.12999987602233887], ['yolov8x', 'WAFHW379', 0.3509988784790039], ['yolov8x_charen', 'HAFHH379', 0.5460000038146973], 0.1939983367919922, ['pytesseract', '-', 0.1939983367919922], ['easyocr', 'HAFzHH 3791', 0.12600016593933105], ['yolov8x', 'RAFHW379', 0.38900017738342285], ['yolov8x_charen', 'HAFHH379', 0.3229999542236328], 0.20499777793884277, ['pytesseract', 'HAFHW379', 0.20499777793884277], ['easyocr', '#AFchk 3791', 0.12800145149230957], ['yolov8x', 'WAFHW379', 0.28600215911865234], ['yolov8x_charen', 'HAFHH379', 0.36499929428100586], 0.1979999542236328, ['pytesseract', 'HAFHW3279', 0.1979999542236328], ['easyocr', '#AFeHH 379]', 0.12799906730651855], ['yolov8x', 'WAFHW379', 0.295001745223999], ['yolov8x_charen', 'WAFHH379', 0.28100109100341797], 0.14599919319152832, ['pytesseract', 'WAFSHH379', 0.14599919319152832], ['easyocr', 'HAFshk 379', 0.1210012435913086], ['yolov8x', 'WAFHW379', 0.42400026321411133], ['yolov8x_charen', 'MAFHH379', 0.40199899673461914], 0.17003607749938965, ['pytesseract', '-', 0.17003607749938965], ['easyocr', 'KAF sHH 379|', 0.12996482849121094], ['yolov8x', 'HAFHW379', 0.42696237564086914], ['yolov8x_charen', 'HAFHH379', 0.32000231742858887], 0.1920623779296875, ['pytesseract', '-', 0.1920623779296875], ['easyocr', 'HHFchH 379', 0.1269359588623047], ['yolov8x', 'WAFHW379', 0.41900157928466797], ['yolov8x_charen', 'HAFHH379', 0.4139993190765381], 0.17403125762939453, ['pytesseract', 'IWAFSHW379', 0.17403125762939453], ['easyocr', 'KIFzhk 379', 0.13492608070373535], ['yolov8x', 'WAFHW379', 0.3900001049041748], ['yolov8x_charen', 'HAFHH379', 0.42200136184692383], 0.17399930953979492, ['pytesseract', 'WAFHW379', 0.17399930953979492], ['easyocr', 'KAFshH 379', 0.11500310897827148], ['yolov8x', 'WAFHW379', 0.5629994869232178], ['yolov8x_charen', 'HAFHH379', 0.4980013370513916], 0.22196078300476074, ['pytesseract', '-', 0.22196078300476074], ['easyocr', '[AFcHH 3791', 0.169999361038208], ['yolov8x', 'HAFHW379', 0.45229053497314453], ['yolov8x_charen', 'HAFHH379', 0.5919992923736572], 0.19699954986572266, ['pytesseract', 'IWAFSHH379', 0.19699954986572266], ['easyocr', 'BAFeHH 3791', 0.14100360870361328], ['yolov8x', 'HAFHW379', 0.6060001850128174], ['yolov8x_charen', 'HAFHH379', 0.5360000133514404], 0.1709613800048828, ['pytesseract', 'IWAFSHH379', 0.1709613800048828], ['easyocr', 'BAF2Hk 379]', 0.17304301261901855], ['yolov8x', 'HAFHW379', 0.3769993782043457], ['yolov8x_charen', 'HAFHH379', 0.5209999084472656], 0.19349312782287598, ['pytesseract', '-', 0.19349312782287598], ['easyocr', 'HAFekk 379|', 0.11599922180175781], ['yolov8x', 'HAFHW379', 0.3190028667449951], ['yolov8x_charen', 'HAFHH379', 0.39262938499450684], 0.21977901458740234, ['pytesseract', 'WAFHW379', 0.21977901458740234], ['easyocr', 'JHAFcHH 379]', 0.11966562271118164], ['yolov8x', 'HAFHW379', 0.48458099365234375], ['yolov8x_charen', 'HAFHH379', 0.3375544548034668], 0.18103504180908203, ['pytesseract', '-', 0.18103504180908203], ['easyocr', 'HAFskK 379]', 0.1315135955810547], ['yolov8x', 'WAFHW379', 0.3510556221008301], ['yolov8x_charen', 'HAFHH379', 0.3285369873046875], 0.1685173511505127, ['pytesseract', 'HAFHW379', 0.1685173511505127], ['easyocr', '[AF2HH 3791', 0.1340181827545166], ['yolov8x', 'WAFHW379', 0.42104029655456543], ['yolov8x_charen', 'HAFHH379', 0.5860648155212402], 0.20603251457214355, ['pytesseract', 'HAFHH379', 0.20603251457214355], ['easyocr', 'IMAFoHk 379]', 0.13350915908813477], ['yolov8x', 'WAFHW379', 0.5105490684509277], ['yolov8x_charen', 'MAFHH379', 0.46355557441711426], 0.1830310821533203, ['pytesseract', 'KAFOHW379', 0.1830310821533203], ['easyocr', 'KAF 2HH 379]', 0.17902255058288574], ['yolov8x', 'AFHW379', 0.6019997596740723], ['yolov8x_charen', 'HAFHH379', 0.46900033950805664], 0.1919994354248047, ['pytesseract', 'HAF', 0.1919994354248047], ['easyocr', 'HAFsHk379,', 0.1809985637664795], ['yolov8x', 'WAFHW379', 0.4649996757507324], ['yolov8x_charen', 'MAFHH379', 0.48200011253356934], 0.14400053024291992, ['pytesseract', '-', 0.14400053024291992], ['easyocr', 'IBAF cHk 379|', 0.12299966812133789], ['yolov8x', 'WAFHW379', 0.4309999942779541], ['yolov8x_charen', 'MAFHH379', 0.4519996643066406], 0.1490023136138916, ['pytesseract', '-', 0.1490023136138916], ['easyocr', 'JaFsHH 379|', 0.13499927520751953], ['yolov8x', 'RAFHW379', 0.5590019226074219], ['yolov8x_charen', 'HAFHH379U', 0.5529994964599609], 0.17400169372558594, ['pytesseract', '-', 0.17400169372558594], ['easyocr', 'JF;kh 379|', 0.1399979591369629], ['yolov8x', '', 0.5560004711151123], ['yolov8x_charen', '', 0.5239999294281006], 0.18999862670898438, ['pytesseract', '-', 0.18999862670898438], ['easyocr', 'ha', 0.38100123405456543], ['yolov8x', '', 0.6519978046417236], ['yolov8x_charen', '', 0.8463952541351318], 0.16699910163879395, ['pytesseract', '-', 0.16699910163879395], ['easyocr', '', 0.27300024032592773], ['yolov8x', '', 0.4869999885559082], ['yolov8x_charen', 'E', 0.509000301361084], 0.14500188827514648, ['pytesseract', '-', 0.14500188827514648], ['easyocr', '', 0.2649998664855957], ['yolov8x', '4', 0.5220000743865967], ['yolov8x_charen', '', 0.5129990577697754], 0.16500115394592285, ['pytesseract', '-', 0.16500115394592285], ['easyocr', '[7J2', 0.2820003032684326], ['yolov8x', '3NC352A', 0.5300004482269287], ['yolov8x_charen', '335', 0.46903419494628906], 0.15200185775756836, ['pytesseract', 'SEM35534', 0.15200185775756836], ['easyocr', '84)3525', 0.3579990863800049], ['yolov8x', 'GN3353A', 0.48800063133239746], ['yolov8x_charen', '433234', 0.5570008754730225], 0.16819500923156738, ['pytesseract', 'WGM33534', 0.16819500923156738], ['easyocr', 'HcX JJ534', 0.2110004425048828], ['yolov8x', 'WGM3353A', 0.5600306987762451], ['yolov8x_charen', 'MCM33234', 0.5269393920898438], 0.178999662399292, ['pytesseract', 'IWGM3353A', 0.178999662399292], ['easyocr', 'IGH 3353A', 0.3040008544921875], ['yolov8x', 'WGM3353A', 0.6020009517669678], ['yolov8x_charen', 'MCM3353A', 0.6289975643157959], 0.17392492294311523, ['pytesseract', '-', 0.17392492294311523], ['easyocr', 'NGM 3353A', 0.18400096893310547], ['yolov8x', 'WGM3353A', 0.5440011024475098], ['yolov8x_charen', 'MCM3353A', 0.6580002307891846], 0.17800092697143555, ['pytesseract', 'HGM33534', 0.17800092697143555], ['easyocr', '06H 3353A', 0.12900042533874512], ['yolov8x', '3353A', 0.8759987354278564], ['yolov8x_charen', '33534', 0.7830009460449219], 0.16204047203063965, ['pytesseract', '-', 0.16204047203063965], ['easyocr', '33534', 0.12196135520935059], ['yolov8x', '5T', 0.5019609928131104], ['yolov8x_charen', '', 0.48699951171875], 0.1510004997253418, ['pytesseract', '-', 0.1510004997253418], ['easyocr', 'E2 EuN', 0.2859988212585449], ['yolov8x', 'S0CT114', 0.4740002155303955], ['yolov8x_charen', '0CT', 0.43200039863586426], 0.15799999237060547, ['pytesseract', '-', 0.15799999237060547], ['easyocr', 'SoDL', 0.3620021343231201], ['yolov8x', 'SOCT114', 0.4529688358306885], ['yolov8x_charen', '2OCT4', 0.508965253829956], 0.1869978904724121, ['pytesseract', '-', 0.1869978904724121], ['easyocr', 'SOTTT', 0.23600077629089355], ['yolov8x', 'SOCT114', 0.4589667320251465], ['yolov8x_charen', '2OCT114', 0.4370002746582031], 0.17799878120422363, ['pytesseract', 'BSOCT114', 0.17799878120422363], ['easyocr', '5O CTIIG', 0.3749997615814209], ['yolov8x', '8EC', 0.5560014247894287], ['yolov8x_charen', '', 0.792996883392334], 0.1660001277923584, ['pytesseract', 'ES', 0.1660001277923584], ['easyocr', '', 0.08199906349182129], ['yolov8x', '0EC', 0.7310643196105957], ['yolov8x_charen', '09', 0.7849352359771729], 0.16199874877929688, ['pytesseract', 'EC', 0.16199874877929688], ['easyocr', 'I@ec@', 0.15200138092041016], ['yolov8x', 'SOCT114', 0.45496416091918945], ['yolov8x_charen', '2OCT114', 0.4660000801086426], 0.15799808502197266, ['pytesseract', 'WSO3CT114', 0.15799808502197266], ['easyocr', 'S0', 0.32199978828430176], ['yolov8x', 'SOCT114', 0.5620009899139404], ['yolov8x_charen', 'SOCT114', 0.53999924659729], 0.15899944305419922, ['pytesseract', 'WS05CT114', 0.15899944305419922], ['easyocr', '5OCTIq]', 0.22899985313415527], ['yolov8x', '0EC', 0.7319996356964111], ['yolov8x_charen', '08', 0.556999921798706], 0.14999985694885254, ['pytesseract', '-', 0.14999985694885254], ['easyocr', 'IUGC@', 0.1900005340576172], ['yolov8x', 'SOCT114', 0.4777042865753174], ['yolov8x_charen', 'S0CT114', 0.44464635848999023], 0.15001559257507324, ['pytesseract', 'RSOCT114', 0.15001559257507324], ['easyocr', 'SOsCTI1q', 0.18701982498168945], ['yolov8x', '0EC', 0.8446009159088135], ['yolov8x_charen', '08', 0.7941970825195312], 0.17246675491333008, ['pytesseract', 'Z', 0.17246675491333008], ['easyocr', 'IVGG@', 0.1890239715576172], ['yolov8x', 'SOCT114', 0.29500460624694824], ['yolov8x_charen', 'S0CT114', 0.6766233444213867], 0.28354406356811523, ['pytesseract', 'WS0CT114', 0.28354406356811523], ['easyocr', 'SO2C7114', 0.2925429344177246], ['yolov8x', '0C', 0.7771220207214355], ['yolov8x_charen', '08', 0.5696282386779785], 0.20803380012512207, ['pytesseract', 'WE', 0.20803380012512207], ['easyocr', 'IUGGo', 0.2060387134552002], ['yolov8x', 'SOCT114', 0.526512622833252], ['yolov8x_charen', 'S0CT114', 0.4460000991821289], 0.1810011863708496, ['pytesseract', 'WSOCT114', 0.1810011863708496], ['easyocr', 'SOeCi114', 0.13400006294250488], ['yolov8x', '0EC', 0.7770001888275146], ['yolov8x_charen', '09', 0.8110001087188721], 0.16500091552734375, ['pytesseract', '-', 0.16500091552734375], ['easyocr', 'JUEG@', 0.21221685409545898], ['yolov8x', 'SOCT114', 0.46899986267089844], ['yolov8x_charen', 'S0CT114', 0.48600101470947266], 0.17100024223327637, ['pytesseract', 'SOCT114', 0.17100024223327637], ['easyocr', 'SOcCI1G', 0.14699935913085938], ['yolov8x', 'EC', 0.6360001564025879], ['yolov8x_charen', '9', 0.6349976062774658], 0.18400073051452637, ['pytesseract', '-', 0.18400073051452637], ['easyocr', 'IVGG@', 0.17400097846984863], ['yolov8x', '', 0.5119993686676025], ['yolov8x_charen', '', 0.49500131607055664], 0.15000033378601074, ['pytesseract', '-', 0.15000033378601074], ['easyocr', '', 0.09399890899658203], ['yolov8x', 'SOCT114', 0.41100049018859863], ['yolov8x_charen', 'S0CT114', 0.41299867630004883], 0.1660001277923584, ['pytesseract', 'WS0CT114', 0.1660001277923584], ['easyocr', '5O2C7114', 0.1379997730255127], ['yolov8x', 'C', 0.6210002899169922], ['yolov8x_charen', '8', 0.8140361309051514], 0.17499923706054688, ['pytesseract', '-', 0.17499923706054688], ['easyocr', 'VGG@', 0.22300267219543457], ['yolov8x', '', 0.6550014019012451], ['yolov8x_charen', '', 0.6739990711212158], 0.1550004482269287, ['pytesseract', '-', 0.1550004482269287], ['easyocr', '', 0.09599971771240234], ['yolov8x', 'SOCT114', 0.500999927520752], ['yolov8x_charen', 'S0CT114', 0.4389986991882324], 0.17399978637695312, ['pytesseract', 'RS0CT114', 0.17399978637695312], ['easyocr', 'SOcCT114', 0.14300203323364258], ['yolov8x', '0C', 0.7159361839294434], ['yolov8x_charen', '08', 0.6229989528656006], 0.1999349594116211, ['pytesseract', '-', 0.1999349594116211], ['easyocr', 'IUGG@', 0.24100160598754883], ['yolov8x', '', 0.632000207901001], ['yolov8x_charen', '', 0.5919914245605469], 0.15899896621704102, ['pytesseract', '-', 0.15899896621704102], ['easyocr', '', 0.09100031852722168], ['yolov8x', 'SOCT114', 0.3599686622619629], ['yolov8x_charen', 'S0CT114', 0.3020007610321045], 0.16399860382080078, ['pytesseract', 'MS02CT114', 0.16399860382080078], ['easyocr', 'SOeCT14', 0.10900163650512695], ['yolov8x', 'C', 0.7099995613098145], ['yolov8x_charen', '08', 0.7490010261535645], 0.1679997444152832, ['pytesseract', '-', 0.1679997444152832], ['easyocr', 'IVGG@', 0.17200350761413574], ['yolov8x', '', 0.4159994125366211], ['yolov8x_charen', '', 0.5319998264312744], 0.17999839782714844, ['pytesseract', '-', 0.17999839782714844], ['easyocr', '', 0.1300034523010254], ['yolov8x', 'SOCT114', 0.4924335479736328], ['yolov8x_charen', 'S0CT114', 0.5830001831054688], 0.17199969291687012, ['pytesseract', 'RS0CT114', 0.17199969291687012], ['easyocr', 'SO;Ci114', 0.20200061798095703], ['yolov8x', 'EC', 0.8100008964538574], ['yolov8x_charen', '08', 0.8759987354278564], 0.17600011825561523, ['pytesseract', '-', 0.17600011825561523], ['easyocr', 'GvGco', 0.23600006103515625], ['yolov8x', '', 0.6080005168914795], ['yolov8x_charen', '', 0.6699988842010498], 0.15800046920776367, ['pytesseract', '-', 0.15800046920776367], ['easyocr', '', 0.178999662399292], ['yolov8x', 'SOCT114', 0.5740001201629639], ['yolov8x_charen', 'SOCT114', 0.5340001583099365], 0.14500069618225098, ['pytesseract', '-', 0.14500069618225098], ['easyocr', '50 C7114', 0.21399950981140137], ['yolov8x', '0EC', 0.6300003528594971], ['yolov8x_charen', '05', 0.5560002326965332], 0.18300080299377441, ['pytesseract', '-', 0.18300080299377441], ['easyocr', 'JyEcg', 0.15800023078918457], ['yolov8x', '', 0.6439993381500244], ['yolov8x_charen', '', 0.6760005950927734], 0.17100000381469727, ['pytesseract', '-', 0.17100000381469727], ['easyocr', '', 0.10700011253356934]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import IPython\n",
    "import numpy as np\n",
    "from typing import Tuple, Union\n",
    "import math\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "import traceback\n",
    "import re\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from deskew import determine_skew\n",
    "\n",
    "import time\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "import easyocr\n",
    "reader = easyocr.Reader(['en', 'de'])\n",
    "\n",
    "from ultralytics import YOLO\n",
    "yolo_model = YOLO('yolov8m.pt')\n",
    "# plate_model = YOLO('best_plate_model.pt')\n",
    "plate_model = YOLO('best_3.pt')\n",
    "# plate_model = YOLO('vehicle_license_best.pt')\n",
    "characters_model = YOLO('plate_char/yolov8x/weights/best.pt')\n",
    "other_characters_model = YOLO('charenyeni/yolov8x/weights/best.pt')\n",
    "\n",
    "detected_plates = []\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = 'C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract.exe'\n",
    "\n",
    "target_classes = [\"truck\", \"bus\", \"car\", \"train\", \"bicycle\"]\n",
    "\n",
    "characters = \"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ\" # '0123456789abcdefghijklmnopqrstuvwxyz' # \"0123456789ÄÜÖABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "\n",
    "# STN = STNet()\n",
    "# STN.to(device)\n",
    "# STN.load_state_dict(torch.load('LPRNet/weights/Final_STN_model.pth', map_location=lambda storage, loc: storage))\n",
    "# STN.eval()\n",
    "\n",
    "times = []\n",
    "\n",
    "# get grayscale image\n",
    "def get_grayscale(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# noise removal\n",
    "def remove_noise(image):\n",
    "    return cv2.medianBlur(image,5)\n",
    "\n",
    "#thresholding\n",
    "def thresholding(image):\n",
    "    return cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "#dilation\n",
    "def dilate(image):\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    return cv2.dilate(image, kernel, iterations = 1)\n",
    "\n",
    "#erosion\n",
    "def erode(image):\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    return cv2.erode(image, kernel, iterations = 1)\n",
    "\n",
    "#opening - erosion followed by dilation\n",
    "def opening(image):\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    return cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "#canny edge detection\n",
    "def canny(image):\n",
    "    return cv2.Canny(image, 100, 200)\n",
    "\n",
    "#skew correction\n",
    "def deskew(image):\n",
    "    coords = np.column_stack(np.where(image > 0))\n",
    "    angle = cv2.minAreaRect(coords)[-1]\n",
    "    if angle < -45:\n",
    "        angle = -(90 + angle)\n",
    "    else:\n",
    "        angle = -angle\n",
    "    (h, w) = image.shape[:2]\n",
    "    center = (w // 2, h // 2)\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    rotated = cv2.warpAffine(image, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
    "    return rotated\n",
    "\n",
    "def compute_skew(src_img):\n",
    "    if len(src_img.shape) == 3:\n",
    "        h, w, _ = src_img.shape\n",
    "    elif len(src_img.shape) == 2:\n",
    "        h, w = src_img.shape\n",
    "    else:\n",
    "        print('unsupported image type')\n",
    "    img = cv2.medianBlur(src_img, 3)\n",
    "    edges = cv2.Canny(img,  threshold1 = 30,  threshold2 = 100, apertureSize = 3, L2gradient = True)\n",
    "    lines = cv2.HoughLinesP(edges, 1, math.pi/180, 30, minLineLength=w / 4.0, maxLineGap=h/4.0)\n",
    "    angle = 0.0\n",
    "    nlines = lines.size\n",
    "    #print(nlines)\n",
    "    cnt = 0\n",
    "    for x1, y1, x2, y2 in lines[0]:\n",
    "        ang = np.arctan2(y2 - y1, x2 - x1)\n",
    "        #print(ang)\n",
    "        if math.fabs(ang) <= 30: # excluding extreme rotations\n",
    "            angle += ang\n",
    "            cnt += 1\n",
    "    if cnt == 0:\n",
    "        return 0.0\n",
    "    return (angle / cnt)*180/math.pi\n",
    "\n",
    "def rotate_image(image, angle):\n",
    "    image_center = tuple(np.array(image.shape[1::-1]) / 2)\n",
    "    rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n",
    "    result = cv2.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
    "    return result\n",
    "\n",
    "def get_deskew_angle(image):\n",
    "    coords = np.column_stack(np.where(image > 0))\n",
    "    angle = cv2.minAreaRect(coords)[-1]\n",
    "    if angle<-45: angle=-angle\n",
    "    return angle\n",
    "\n",
    "def deskew_image(image, angle):\n",
    "    (h, w) = image.shape[:2]\n",
    "    center = (w // 2, h // 2)\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    return cv2.warpAffine(image, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
    "\n",
    "#template matching\n",
    "def match_template(image, template):\n",
    "    return cv2.matchTemplate(image, template, cv2.TM_CCOEFF_NORMED)\n",
    "\n",
    "def rotate(\n",
    "        image: np.ndarray, angle: float, background: Union[int, Tuple[int, int, int]]\n",
    ") -> np.ndarray:\n",
    "    old_width, old_height = image.shape[:2]\n",
    "    angle_radian = math.radians(angle)\n",
    "    width = abs(np.sin(angle_radian) * old_height) + abs(np.cos(angle_radian) * old_width)\n",
    "    height = abs(np.sin(angle_radian) * old_width) + abs(np.cos(angle_radian) * old_height)\n",
    "\n",
    "    image_center = tuple(np.array(image.shape[1::-1]) / 2)\n",
    "    rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n",
    "    rot_mat[1, 2] += (width - old_width) / 2\n",
    "    rot_mat[0, 2] += (height - old_height) / 2\n",
    "    return cv2.warpAffine(image, rot_mat, (int(round(height)), int(round(width))), borderValue=background)\n",
    "\n",
    "# NN Layer License Plate Recognition \"OCR\"\n",
    "def process_license(processed_frame, bounding_box, name, confidence, parentName, parentConfidence):\n",
    "    x1, y1, x2, y2 = [int(x) for x in bounding_box]\n",
    "    cv2.rectangle(processed_frame,(x1,y1),(x2,y2),(255,0,255),2)\n",
    "    cv2.putText(processed_frame, '{} {:.2f}%'.format(name.upper(), confidence*100),(x1+10,y1-15),0,0.9,(255,0,255),2)\n",
    "\n",
    "    # Rotation\n",
    "    # license_frame = deskew(processed_frame[y1:y2,x1:x2])\n",
    "    license_frame = processed_frame[y1:y2,x1:x2]\n",
    "\n",
    "    plt.imshow(license_frame)\n",
    "    plt.show()\n",
    "\n",
    "    plate_parts=[]\n",
    "    plate_text=\"\"\n",
    "\n",
    "    start_time = time.time()\n",
    "    results = characters_model(license_frame, agnostic_nms=True, verbose=False, device=device)[0]\n",
    "    total_time = time.time() - start_time\n",
    "    # cv2.putText(processed_frame, '{:.3f}sec'.format(total_time),(x1+100,y1+200),0,0.7,(0,0,255),2)\n",
    "    \n",
    "    for result in results:\n",
    "        detection_count = result.boxes.shape[0]\n",
    "        for i in range(detection_count):\n",
    "            cls = int(result.boxes.cls[i].item())\n",
    "            name2 = result.names[cls]\n",
    "            confidence2 = float(result.boxes.conf[i].item())\n",
    "            bounding_box2 = result.boxes.xyxy[i].cpu().numpy()\n",
    "            a1, b1, a2, b2 = [int(x) for x in bounding_box2]\n",
    "            # Ensure a1 < a2 and b1 < b2\n",
    "            a1, a2 = min(a1, a2), max(a1, a2)\n",
    "            b1, b2 = min(b1, b2), max(b1, b2)\n",
    "            if confidence2>0.3:\n",
    "                # cv2.rectangle(processed_frame,(x1+a1,y1+b1),(x1+a2,y1+b2),(0,0,255),1)\n",
    "                # cv2.putText(processed_frame, '{}'.format(name2),(x1+a1,y1+b1+75),0,0.9,(0,0,255),2)\n",
    "                # cv2.putText(processed_frame, '{:.2f}%'.format(confidence2*100),(x1+a1,y1+b1+100+25*i),0,0.7,(0,0,255),2)\n",
    "                plate_parts.append([a1,b1,name2])\n",
    "\n",
    "    sorted_list = sorted(plate_parts,key=lambda l:l[0])\n",
    "    for part in range(len(sorted_list)):\n",
    "        if sorted_list[part][2]!=\"undefined\":\n",
    "            plate_text+=sorted_list[part][2]\n",
    "    print(\"yolov8x\", plate_text, total_time)\n",
    "    times.append([\"yolov8x\", plate_text,total_time])\n",
    "\n",
    "    plate_parts=[]\n",
    "    plate_text=\"\"\n",
    "    \n",
    "    start_time = time.time()\n",
    "    results = other_characters_model(license_frame, agnostic_nms=True, verbose=False, device=device)[0]\n",
    "    total_time = time.time() - start_time\n",
    "    # cv2.putText(processed_frame, '{:.3f}sec'.format(total_time),(x1+100,y1+200),0,0.7,(0,0,255),2)\n",
    "    \n",
    "    for result in results:\n",
    "        detection_count = result.boxes.shape[0]\n",
    "        for i in range(detection_count):\n",
    "            cls = int(result.boxes.cls[i].item())\n",
    "            name2 = result.names[cls]\n",
    "            confidence2 = float(result.boxes.conf[i].item())\n",
    "            bounding_box2 = result.boxes.xyxy[i].cpu().numpy()\n",
    "            a1, b1, a2, b2 = [int(x) for x in bounding_box2]\n",
    "            # Ensure a1 < a2 and b1 < b2\n",
    "            a1, a2 = min(a1, a2), max(a1, a2)\n",
    "            b1, b2 = min(b1, b2), max(b1, b2)\n",
    "            if confidence2>0.3:\n",
    "                # cv2.rectangle(processed_frame,(x1+a1,y1+b1),(x1+a2,y1+b2),(0,0,255),1)\n",
    "                # cv2.putText(processed_frame, '{}'.format(name2),(x1+a1,y1+b1+75),0,0.9,(0,0,255),2)\n",
    "                # cv2.putText(processed_frame, '{:.2f}%'.format(confidence2*100),(x1+a1,y1+b1+100+25*i),0,0.7,(0,0,255),2)\n",
    "                plate_parts.append([a1,b1,name2])\n",
    "\n",
    "    sorted_list = sorted(plate_parts,key=lambda l:l[0])\n",
    "    for part in range(len(sorted_list)):\n",
    "        if sorted_list[part][2]!=\"undefined\":\n",
    "            plate_text+=sorted_list[part][2]\n",
    "    print(\"yolov8x_charen\", plate_text, total_time)\n",
    "    times.append([\"yolov8x_charen\", plate_text,total_time])\n",
    "\n",
    "    grayscaled = get_grayscale(license_frame) # get_grayscale(np.array(license_frame))\n",
    "    # angle = determine_skew(grayscaled)\n",
    "    threshholded = thresholding(grayscaled) # deskew_image(thresholding(grayscaled), angle)\n",
    "\n",
    "    # newdata=pytesseract.image_to_osd(threshholded)\n",
    "    # angle=float(re.search('(?<=Rotate: )\\d+', newdata).group(0))\n",
    "    # print('osd angle:',angle)\n",
    "\n",
    "    # angle = compute_skew(thresholding(grayscaled))\n",
    "    # threshholded = rotate_image(thresholding(grayscaled), angle)\n",
    "    # dilated = dilate(threshholded)\n",
    "    # plt.imshow(deskew(threshholded))\n",
    "\n",
    "    # print(angle)\n",
    "    plt.imshow(threshholded)\n",
    "    plt.show()\n",
    "\n",
    "    max_conf = 0.0\n",
    "    best_text = \"\"\n",
    "\n",
    "    start_time = time.time()\n",
    "    results = pytesseract.image_to_data(threshholded, config='-c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789')\n",
    "    end_time = time.time() - start_time\n",
    "    times.append(end_time)\n",
    "    # NN Layer License Plate Recognition \"Dummy OCR\"\n",
    "\n",
    "    parsedLines = results.split('\\n')\n",
    "    best_depth = len(parsedLines)-2\n",
    "    for line in parsedLines:\n",
    "        params = line.split()\n",
    "        if len(params)==12 and float(params[10].replace('conf','0.0'))>=max_conf:\n",
    "            max_conf = float(params[10].replace('conf','0.0'))\n",
    "            best_text = params[11] if params[11]!=\"text\" else \"-\"\n",
    "            if max_conf>=0.0 and len(best_text)>0:\n",
    "                detected_plates.append([parentConfidence*100, parentName.upper(), confidence*100, name.upper(), max_conf, best_text, \"pytesseract\"])\n",
    "    # cv2.putText(processed_frame, '{} {:.2f}%'.format(\"[tesse]: \"+best_text, max_conf),(x1+10,y2+25),0,0.9,(0,0,255),3)\n",
    "    print(\"pytesseract\", best_text, end_time)\n",
    "    times.append([\"pytesseract\", best_text,end_time])\n",
    "\n",
    "    max_conf = 0.0\n",
    "    best_text = \"\"\n",
    "\n",
    "    start_time = time.time()\n",
    "    result = reader.readtext(threshholded)\n",
    "    end_time = time.time() - start_time\n",
    "    text = \"\"\n",
    "    conf = 0.0\n",
    "    for res in result:\n",
    "        if res[2]>conf:\n",
    "            conf=res[2]\n",
    "            text=res[1]\n",
    "            if res[2]*100>max_conf:\n",
    "                max_conf = res[2]*100\n",
    "                best_text = res[1]\n",
    "                if max_conf>=0.0 and len(best_text)>0:\n",
    "                    detected_plates.append([parentConfidence*100, parentName.upper(), confidence*100, name.upper(), max_conf, best_text, \"easyocr\"])\n",
    "    # cv2.putText(processed_frame, '{} {:.2f}%'.format(\"[easy]: \"+str(text), conf*100),(x1+10,y2+57),0,0.9,(200,200,200),3)\n",
    "    print(\"easyocr\", text, end_time)\n",
    "    times.append([\"easyocr\", text,end_time])\n",
    "\n",
    "# NN Layer Vehicle Found -> License Detection\n",
    "def process_vehicle(processed_frame, bounding_box, name, confidence):\n",
    "\n",
    "    # Yolov8n Bounding Boxes\n",
    "    x1, y1, x2, y2 = [int(x) for x in bounding_box]\n",
    "    cv2.rectangle(processed_frame,(x1,y1),(x2,y2),(0,255,255),2)\n",
    "\n",
    "    # cv2.putText(processed_frame, '{} {:.2f}%'.format(name.upper(), confidence*100),(x1+10,y1+25),0,0.8,(0,255,255),2)\n",
    "    vehicle_frame = processed_frame[y1:y2,x1:x2]\n",
    "    results = plate_model(vehicle_frame, agnostic_nms=True, verbose=False)[0]\n",
    "    for result in results:\n",
    "        detection_count = result.boxes.shape[0]\n",
    "        for i in range(detection_count):\n",
    "            cls = int(result.boxes.cls[i].item())\n",
    "            name2 = result.names[cls]\n",
    "            confidence2 = float(result.boxes.conf[i].item())\n",
    "            bounding_box2 = result.boxes.xyxy[i].cpu().numpy()\n",
    "            a1, b1, a2, b2 = [int(x) for x in bounding_box2]\n",
    "            # Ensure a1 < a2 and b1 < b2\n",
    "            a1, a2 = min(a1, a2), max(a1, a2)\n",
    "            b1, b2 = min(b1, b2), max(b1, b2)\n",
    "            # if name2==\"License_Plate\": process_license(processed_frame, [x1+a1, y1+b1, x1+a2, y1+b2], name2, confidence2, name, confidence)\n",
    "            process_license(processed_frame, [x1+a1, y1+b1, x1+a2, y1+b2], name2, confidence2, name, confidence)\n",
    "\n",
    "# NN Layer Other Objects Detected [Not target classes]\n",
    "def process_detection(processed_frame, bounding_box, name, confidence):\n",
    "    x1, y1, x2, y2 = [int(x) for x in bounding_box]\n",
    "    cv2.rectangle(processed_frame,(x1,y1),(x2,y2),(255,255,0),2)\n",
    "    cv2.putText(processed_frame, '{} {:.2f}%'.format(name.upper(), confidence*100),(x1+10,y1+25),0,0.8,(255,255,0),2)\n",
    "\n",
    "# NN Layer Yolov8 Detection\n",
    "def yolov8n_objects(frame):\n",
    "    processed_frame = frame\n",
    "    start_time = time.time()\n",
    "    results = yolo_model(processed_frame, agnostic_nms=True, verbose=False)[0]\n",
    "    end_time = time.time()\n",
    "    processing_time = end_time - start_time\n",
    "    # print(f\"Processing time yolov8: {processing_time:.3f} seconds\")  # Output processing time\n",
    "    for result in results:\n",
    "        detection_count = result.boxes.shape[0]\n",
    "        for i in range(detection_count):\n",
    "            cls = int(result.boxes.cls[i].item())\n",
    "            name = result.names[cls]\n",
    "            confidence = float(result.boxes.conf[i].item())\n",
    "            bounding_box = result.boxes.xyxy[i].cpu().numpy()\n",
    "            x1, y1, x2, y2 = [int(x) for x in bounding_box]\n",
    "            # Ensure x1 < x2 and y1 < y2\n",
    "            x1, x2 = min(x1, x2), max(x1, x2)\n",
    "            y1, y2 = min(y1, y2), max(y1, y2)\n",
    "            if name in target_classes: process_vehicle(processed_frame, bounding_box, name, confidence)\n",
    "            else: process_detection(processed_frame, bounding_box, name, confidence)\n",
    "    return processed_frame\n",
    "\n",
    "def process_frame(frame):\n",
    "    processed_frame = yolov8n_objects(frame)\n",
    "    # processed_frame = cv2.flip(processed_frame, 1)\n",
    "    return processed_frame\n",
    "\n",
    "def handleFrame(frame):\n",
    "    processed_frame = process_frame(frame)\n",
    "    _, processed_frame = cv2.imencode('.jpeg', processed_frame)\n",
    "    display_handle.update(IPython.display.Image(data=processed_frame.tobytes()))\n",
    "    IPython.display.clear_output(wait=True)\n",
    "\n",
    "def handleRelease():\n",
    "    cam.release()\n",
    "    print(\"Source released.\")\n",
    "    correct_plates = []\n",
    "    better_plates = []\n",
    "    best_plate = []\n",
    "    most_repeated_plates = []\n",
    "    best_repeated_plates = []\n",
    "    highest_score = 0.0\n",
    "    if len(detected_plates)>0:\n",
    "        repetitions = {}\n",
    "        count, item = 0, ''\n",
    "        for plate in detected_plates:\n",
    "            if plate[0]>50.0 and plate[2]>50.0 and plate[4]>50.0: correct_plates.append(plate)\n",
    "            if plate[0]>70.0 and plate[2]>70.0 and plate[4]>70.0: better_plates.append(plate)\n",
    "            if plate[0] + plate[2] + plate[4] > highest_score:\n",
    "                highest_score = plate[0] + plate[2] + plate[4]\n",
    "                best_plate = plate\n",
    "            repetitions[plate[5]] = repetitions.get(plate[5], 0) + 1\n",
    "            if repetitions[plate[5]]>count: count, item = repetitions[plate[5]], plate[5]\n",
    "        if len(repetitions.keys())>0:\n",
    "            for itm in repetitions.keys():\n",
    "                if repetitions[itm]==count:\n",
    "                    repeated_detected = [plate for plate in detected_plates if plate[5]==itm]\n",
    "                    best_percentages = []\n",
    "                    for plate in repeated_detected:\n",
    "                        if len(best_percentages)==0: best_percentages=plate\n",
    "                        elif (plate[0] + plate[2] + plate[4])/3.0>(best_percentages[0] + best_percentages[2] + best_percentages[4])/3.0: best_percentages=plate\n",
    "                    most_repeated_plates.append(best_percentages)\n",
    "        if len(most_repeated_plates)>0:\n",
    "            for plate in most_repeated_plates:\n",
    "                best_repeated = []\n",
    "                if len(best_repeated)==0: best_repeated=plate\n",
    "                elif (plate[0] + plate[2] + plate[4])/3.0>(best_repeated[0] + best_repeated[2] + best_repeated[4])/3.0: best_repeated=plate\n",
    "            best_repeated_plates.append(best_repeated)\n",
    "    print(\"\\nDetected Plates: \\n\", np.matrix(detected_plates))\n",
    "    print(\"\\nCorrectly Detected Plates: \\n\", np.matrix(correct_plates))\n",
    "    print(\"\\nBetter Detected Plates: \\n\", np.matrix(better_plates))\n",
    "    print(\"\\nBest Detected Plate: \\n\", np.matrix(best_plate))\n",
    "    print(\"\\nMost Repeated Plates: \\n\", np.matrix(most_repeated_plates))\n",
    "    print(\"\\nBest Repeated Plate: \\n\", np.matrix(best_repeated_plates))\n",
    "\n",
    "    print(\"times\",times)\n",
    "\n",
    "inputType=\"video\"\n",
    "# cam = cv2.VideoCapture(0)\n",
    "source = \"data/video/sample.MP4\" if inputType==\"video\" else 0\n",
    "cam = cv2.VideoCapture(source)\n",
    "display_handle=display(None, display_id=True)\n",
    "every = 60\n",
    "\n",
    "start = 0 if source!=0 else -1\n",
    "end = int(cam.get(cv2.CAP_PROP_FRAME_COUNT)) if source!=0 else -1\n",
    "if source!=0: cam.set(1, start)\n",
    "\n",
    "frameCount=start\n",
    "while_safety=0\n",
    "saved_count=0\n",
    "\n",
    "if not cam.isOpened(): print(\"Error: Could not open source.\")\n",
    "else:\n",
    "    try:\n",
    "        while True if end<0 else frameCount<end:\n",
    "            _, frame = cam.read()\n",
    "            if frame is None:\n",
    "                if source!=0:\n",
    "                    if while_safety > 2000: break\n",
    "                    while_safety += 1\n",
    "                    continue\n",
    "                else:\n",
    "                    print(\"Error: Could not capture frame.\")\n",
    "                    cam.release()\n",
    "                    break\n",
    "\n",
    "            if every>0:\n",
    "                if (frameCount+1)%math.floor(every) == 0:\n",
    "                    while_safety = 0\n",
    "                    handleFrame(frame)\n",
    "            else:\n",
    "                while_safety=0\n",
    "                handleFrame(frame)\n",
    "            frameCount += 1\n",
    "        handleRelease()\n",
    "    except KeyboardInterrupt:\n",
    "        handleRelease()\n",
    "    except:\n",
    "        print(\"Unknown error.\")\n",
    "        try:\n",
    "            cam.release()\n",
    "            raise TypeError(\"Error: Source could not be released.\")\n",
    "        except:\n",
    "            pass\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "67d68c84-e9a9-48b5-a47c-204f34051629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source released.\n",
      "\n",
      "['K0S0922E', 'BA544', 'WI460KA', '0PR8X14', '', 'K0S0922E', 'BA25466', 'AY', 'SB3UJ7', 'OPR8X14', 'SJ248V']\n"
     ]
    }
   ],
   "source": [
    "# Neuronal Network Layered Stream with the better fps\n",
    "import cv2\n",
    "import IPython\n",
    "import numpy as np\n",
    "from typing import Tuple, Union\n",
    "import math\n",
    "from PIL import Image\n",
    "# import pytesseract\n",
    "import traceback\n",
    "import time\n",
    "\n",
    "import torch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "from ultralytics import YOLO\n",
    "model = YOLO('yolov8x.pt')\n",
    "plate_model = YOLO('vehicle_license_best.pt')\n",
    "characters_model = YOLO('plate_char/yolov8x/weights/best.pt')\n",
    "\n",
    "detected_plates = []\n",
    "\n",
    "# pytesseract.pytesseract.tesseract_cmd = 'C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract.exe'\n",
    "\n",
    "target_classes = [\"truck\", \"bus\", \"car\", \"train\", \"bicycle\"]\n",
    "\n",
    "# NN Layer License Plate Recognition \"OCR\"\n",
    "def process_license(processed_frame, bounding_box, name, confidence, parentName, parentConfidence, start_time, step_time):\n",
    "    x1, y1, x2, y2 = [int(x) for x in bounding_box]\n",
    "    cv2.rectangle(processed_frame,(x1,y1),(x2,y2),(255,0,255),2)\n",
    "    cv2.putText(processed_frame, '{} {:.2f}%'.format(name.upper(), confidence*100),(x1+10,y1-15),0,0.7,(255,0,255))\n",
    "\n",
    "    license_frame = processed_frame[y1:y2,x1:x2]\n",
    "\n",
    "    plate_parts=[]\n",
    "    plate_text=\"\"\n",
    "\n",
    "    results = characters_model(license_frame, agnostic_nms=True, verbose=False, device=device)[0]\n",
    "    # total_time = time.time() - start_time\n",
    "    # cv2.putText(processed_frame, '{:.3f}sec'.format(total_time),(x1+100,y1+200),0,0.7,(0,0,255),2)\n",
    "    \n",
    "    for result in results:\n",
    "        detection_count = result.boxes.shape[0]\n",
    "        for i in range(detection_count):\n",
    "            cls = int(result.boxes.cls[i].item())\n",
    "            name2 = result.names[cls]\n",
    "            confidence2 = float(result.boxes.conf[i].item())\n",
    "            bounding_box2 = result.boxes.xyxy[i].cpu().numpy()\n",
    "            a1, b1, a2, b2 = [int(x) for x in bounding_box2]\n",
    "            # Ensure a1 < a2 and b1 < b2\n",
    "            a1, a2 = min(a1, a2), max(a1, a2)\n",
    "            b1, b2 = min(b1, b2), max(b1, b2)\n",
    "            if confidence2>0.3:\n",
    "                cv2.rectangle(processed_frame,(x1+a1,y1+b1),(x1+a2,y1+b2),(0,0,255),1)\n",
    "                cv2.putText(processed_frame, '{}'.format(name2),(x1+a1,y1+b1+75),0,0.9,(0,0,255),2)\n",
    "                cv2.putText(processed_frame, '{:.2f}%'.format(confidence2*100),(x1+a1,y1+b1+100+25*i),0,0.7,(0,0,255),2)\n",
    "                plate_parts.append([a1,b1,name2])\n",
    "\n",
    "    sorted_list = sorted(plate_parts,key=lambda l:l[0])\n",
    "    for part in range(len(sorted_list)):\n",
    "        if sorted_list[part][2]!=\"undefined\":\n",
    "            plate_text+=sorted_list[part][2]\n",
    "    detected_plates.append(plate_text)\n",
    "\n",
    "# NN Layer Vehicle Found -> License Detection\n",
    "def process_vehicle(processed_frame, bounding_box, name, confidence, start_time):\n",
    "    x1, y1, x2, y2 = [int(x) for x in bounding_box]\n",
    "    cv2.rectangle(processed_frame,(x1,y1),(x2,y2),(0,255,255),2)\n",
    "    cv2.putText(processed_frame, '{} {:.2f}%'.format(name.upper(), confidence*100),(x1+10,y1-15),0,0.7,(0,255,255))\n",
    "    vehicle_frame = processed_frame[y1:y2,x1:x2]\n",
    "    step_time = time.time()\n",
    "    results = plate_model(vehicle_frame, agnostic_nms=True, verbose=False, device=device)[0]\n",
    "    for result in results:\n",
    "        detection_count = result.boxes.shape[0]\n",
    "        for i in range(detection_count):\n",
    "            cls = int(result.boxes.cls[i].item())\n",
    "            name2 = result.names[cls]\n",
    "            confidence2 = float(result.boxes.conf[i].item())\n",
    "\n",
    "            if confidence2 > 0.5:\n",
    "                bounding_box2 = result.boxes.xyxy[i].cpu().numpy()\n",
    "                a1, b1, a2, b2 = [int(x) for x in bounding_box2]\n",
    "                # Ensure a1 < a2 and b1 < b2\n",
    "                a1, a2 = min(a1, a2), max(a1, a2)\n",
    "                b1, b2 = min(b1, b2), max(b1, b2)\n",
    "                # if name2==\"License_Plate\":\n",
    "                process_license(processed_frame, [x1+a1, y1+b1, x1+a2, y1+b2], name2, confidence2, name, confidence, start_time, step_time)\n",
    "\n",
    "# NN Layer Other Objects Detected\n",
    "def process_detection(processed_frame, bounding_box, name, confidence):\n",
    "    x1, y1, x2, y2 = [int(x) for x in bounding_box]\n",
    "    # cv2.rectangle(processed_frame,(x1,y1),(x2,y2),(255,255,0),2)\n",
    "    # cv2.putText(processed_frame, '{} {:.2f}%'.format(name.upper(), confidence*100),(x1+10,y1-15),0,0.7,(255,255,0))\n",
    "\n",
    "# NN Layer Yolov8 Detection\n",
    "def process_frame(frame):\n",
    "    processed_frame = frame\n",
    "    # processed_frame = cv2.flip(processed_frame, 1)\n",
    "    start_time = time.time()\n",
    "    results = model(processed_frame, agnostic_nms=True, verbose=False, device=device)[0]\n",
    "    for result in results:\n",
    "        detection_count = result.boxes.shape[0]\n",
    "        for i in range(detection_count):\n",
    "            cls = int(result.boxes.cls[i].item())\n",
    "            name = result.names[cls]\n",
    "            confidence = float(result.boxes.conf[i].item())\n",
    "            bounding_box = result.boxes.xyxy[i].cpu().numpy()\n",
    "            x1, y1, x2, y2 = [int(x) for x in bounding_box]\n",
    "            # Ensure x1 < x2 and y1 < y2\n",
    "            x1, x2 = min(x1, x2), max(x1, x2)\n",
    "            y1, y2 = min(y1, y2), max(y1, y2)\n",
    "            if name in target_classes: process_vehicle(processed_frame, bounding_box, name, confidence, start_time)\n",
    "            else: process_detection(processed_frame, bounding_box, name, confidence)\n",
    "    return processed_frame\n",
    "\n",
    "def handleFrame(frame):\n",
    "    processed_frame = process_frame(frame)\n",
    "    _, processed_frame = cv2.imencode('.jpeg', processed_frame)\n",
    "    display_handle.update(IPython.display.Image(data=processed_frame.tobytes()))\n",
    "    IPython.display.clear_output(wait=True)\n",
    "\n",
    "def handleRelease():\n",
    "    cam.release()\n",
    "    print(\"Source released.\")\n",
    "    print()\n",
    "    print(detected_plates)\n",
    "    # correct_plates = []\n",
    "    # better_plates = []\n",
    "    # best_plate = []\n",
    "    # most_repeated_plates = []\n",
    "    # best_repeated_plates = []\n",
    "    # highest_score = 0.0\n",
    "    # if len(detected_plates)>0:\n",
    "    #     repetitions = {}\n",
    "    #     count, item = 0, ''\n",
    "    #     for plate in detected_plates:\n",
    "    #         if plate[0]>50.0 and plate[2]>50.0 and plate[4]>50.0: correct_plates.append(plate)\n",
    "    #         if plate[0]>70.0 and plate[2]>70.0 and plate[4]>70.0: better_plates.append(plate)\n",
    "    #         if plate[0] + plate[2] + plate[4] > highest_score:\n",
    "    #             highest_score = plate[0] + plate[2] + plate[4]\n",
    "    #             best_plate = plate\n",
    "    #         repetitions[plate[5]] = repetitions.get(plate[5], 0) + 1\n",
    "    #         if repetitions[plate[5]]>count: count, item = repetitions[plate[5]], plate[5]\n",
    "    #     if len(repetitions.keys())>0:\n",
    "    #         for itm in repetitions.keys():\n",
    "    #             if repetitions[itm]==count:\n",
    "    #                 repeated_detected = [plate for plate in detected_plates if plate[5]==itm]\n",
    "    #                 best_percentages = []\n",
    "    #                 for plate in repeated_detected:\n",
    "    #                     if len(best_percentages)==0: best_percentages=plate\n",
    "    #                     elif (plate[0] + plate[2] + plate[4])/3.0>(best_percentages[0] + best_percentages[2] + best_percentages[4])/3.0: best_percentages=plate\n",
    "    #                 most_repeated_plates.append(best_percentages)\n",
    "    #     if len(most_repeated_plates)>0:\n",
    "    #         for plate in most_repeated_plates:\n",
    "    #             best_repeated = []\n",
    "    #             if len(best_repeated)==0: best_repeated=plate\n",
    "    #             elif (plate[0] + plate[2] + plate[4])/3.0>(best_repeated[0] + best_repeated[2] + best_repeated[4])/3.0: best_repeated=plate\n",
    "    #         best_repeated_plates.append(best_repeated)\n",
    "    # print(\"\\nDetected Plates: \\n\", np.matrix(detected_plates))\n",
    "    # print(\"\\nCorrectly Detected Plates: \\n\", np.matrix(correct_plates))\n",
    "    # print(\"\\nBetter Detected Plates: \\n\", np.matrix(better_plates))\n",
    "    # print(\"\\nBest Detected Plate: \\n\", np.matrix(best_plate))\n",
    "    # print(\"\\nMost Repeated Plates: \\n\", np.matrix(most_repeated_plates))\n",
    "    # print(\"\\nBest Repeated Plate: \\n\", np.matrix(best_repeated_plates))\n",
    "\n",
    "inputType=\"video\"\n",
    "# cam = cv2.VideoCapture(0)\n",
    "source = \"data/video/vecteezy_car-and-truck-traffic-on-the-highway-in-europe-poland_7957364.MP4\" if inputType==\"video\" else 0\n",
    "cam = cv2.VideoCapture(source)\n",
    "display_handle=display(None, display_id=True)\n",
    "every = 30\n",
    "\n",
    "start = 0 if source!=0 else -1\n",
    "end = int(cam.get(cv2.CAP_PROP_FRAME_COUNT)) if source!=0 else -1\n",
    "if source!=0: cam.set(1, start)\n",
    "\n",
    "frameCount=start\n",
    "while_safety=0\n",
    "saved_count=0\n",
    "\n",
    "if not cam.isOpened(): print(\"Error: Could not open source.\")\n",
    "else:\n",
    "    try:\n",
    "        while True if end<0 else frameCount<end:\n",
    "            _, frame = cam.read()\n",
    "            if frame is None:\n",
    "                if source!=0:\n",
    "                    if while_safety > 2000: break\n",
    "                    while_safety += 1\n",
    "                    continue\n",
    "                else:\n",
    "                    print(\"Error: Could not capture frame.\")\n",
    "                    cam.release()\n",
    "                    break\n",
    "\n",
    "            if every>0:\n",
    "                if (frameCount+1)%math.floor(every) == 0:\n",
    "                    while_safety = 0\n",
    "                    handleFrame(frame)\n",
    "            else:\n",
    "                while_safety=0\n",
    "                handleFrame(frame)\n",
    "            frameCount += 1\n",
    "        handleRelease()\n",
    "    except KeyboardInterrupt:\n",
    "        handleRelease()\n",
    "    except:\n",
    "        print(\"Unknown error.\")\n",
    "        try:\n",
    "            cam.release()\n",
    "            raise TypeError(\"Error: Source could not be released.\")\n",
    "        except:\n",
    "            pass\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73d733b9-1f9e-41ee-b83c-cb9948e57499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FasterRCNN(\n",
       "  (transform): GeneralizedRCNNTransform(\n",
       "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
       "  )\n",
       "  (backbone): BackboneWithFPN(\n",
       "    (body): IntermediateLayerGetter(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fpn): FeaturePyramidNetwork(\n",
       "      (inner_blocks): ModuleList(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (layer_blocks): ModuleList(\n",
       "        (0-3): 4 x Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (extra_blocks): LastLevelMaxPool()\n",
       "    )\n",
       "  )\n",
       "  (rpn): RegionProposalNetwork(\n",
       "    (anchor_generator): AnchorGenerator()\n",
       "    (head): RPNHead(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): RoIHeads(\n",
       "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
       "    (box_head): TwoMLPHead(\n",
       "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (box_predictor): FastRCNNPredictor(\n",
       "      (cls_score): Linear(in_features=1024, out_features=91, bias=True)\n",
       "      (bbox_pred): Linear(in_features=1024, out_features=364, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision\n",
    "from torchvision.models.detection import *\n",
    "\n",
    " # DetectionModel(\"FCOS\", \"resnet50_fpn\", fcos_resnet50_fpn, FCOS_ResNet50_FPN_Weights, \"fcos_resnet\", (255,0,0)),\n",
    " #    DetectionModel(\"RetinaNet\", \"resnet50_fpn\", retinanet_resnet50_fpn, RetinaNet_ResNet50_FPN_Weights, \"retinanet_resnet\", (255,255,0)),\n",
    " #    DetectionModel(\"RetinaNet\", \"resnet50_fpn_v2\", retinanet_resnet50_fpn_v2, RetinaNet_ResNet50_FPN_V2_Weights, \"retinanet_resnet_v2\", (0,234,255)),\n",
    " #    DetectionModel(\"FasterRCNN\", \"resnet50_fpn\", fasterrcnn_resnet50_fpn, FasterRCNN_ResNet50_FPN_Weights, \"faster_rcnn_resnet\", (170,0,255)),\n",
    " #    DetectionModel(\"FasterRCNN\", \"resnet50_fpn_v2\", fasterrcnn_resnet50_fpn_v2, FasterRCNN_ResNet50_FPN_V2_Weights, \"faster_rcnn_resnet_v2\", (255,127,0)),\n",
    " #    DetectionModel(\"FasterRCNN\", \"mobilenet_v3_large_fpn\", fasterrcnn_mobilenet_v3_large_fpn, FasterRCNN_MobileNet_V3_Large_FPN_Weights, \"faster_rcnn_mobilenet_v3\", (191,255,0)),\n",
    " #    DetectionModel(\"FasterRCNN\", \"mobilenet_v3_large_320_fpn\", fasterrcnn_mobilenet_v3_large_320_fpn, FasterRCNN_MobileNet_V3_Large_320_FPN_Weights, \"faster_rcnn_mobilenet_v3_320\", (0,149,255)),\n",
    " #    DetectionModel(\"MaskRCNN\", \"resnet50_fpn\", maskrcnn_resnet50_fpn, MaskRCNN_ResNet50_FPN_Weights, \"mask_rcnn_resnet\", (255,0,170)),\n",
    " #    DetectionModel(\"MaskRCNN\", \"resnet50_fpn_v2\", maskrcnn_resnet50_fpn_v2, MaskRCNN_ResNet50_FPN_V2_Weights, \"mask_rcnn_resnet_v2\", (255,212,0)),\n",
    " #    DetectionModel(\"SSD300\", \"vgg16\", ssd300_vgg16, SSD300_VGG16_Weights, \"ssd_vgg16\", (106,255,0)),\n",
    " #    DetectionModel(\"SSDLite320\", \"mobilenet_v3_large\", ssdlite320_mobilenet_v3_large, SSDLite320_MobileNet_V3_Large_Weights, \"ssd_mobilenet_v3\", (0,64,255)),\n",
    "\n",
    "model = fasterrcnn_resnet50_fpn(weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT)\n",
    "model.eval()\n",
    "\n",
    "# Load pre-trained Faster R-CNN\n",
    "# model_faster_rcnn = fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "# model_faster_rcnn.eval()\n",
    "\n",
    "# Load pre-trained Mask R-CNN\n",
    "# model_mask_rcnn = maskrcnn_resnet50_fpn(pretrained=True)\n",
    "# model_mask_rcnn.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8654967c-082e-40bc-bca1-525c866f882e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
